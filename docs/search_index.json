[
["index.html", "Calcul stochastique Chapitre 1 Rappel sur le calcul des probabilités 1.1 Notion de probabilité 1.2 Variables aléatoires 1.3 Espérance mathématique 1.4 Fonctions génératrices des moments 1.5 Fonctions caractéristiques 1.6 Espérance conditionnelle - Variance conditionnelle 1.7 Processus stochastique Exercices", " Calcul stochastique Mohamed Essaied Hamrita 2021 Chapitre 1 Rappel sur le calcul des probabilités 1.1 Notion de probabilité Une notion basique dans la théorie des probabilités est l’expérience aléatoire dont on ne connait pas son résultat en avance. L’ensemble de tous les résultats de l’expérience est l’ensemble des possibles ou encore l’univers et noté \\(\\Omega\\). Un évènement est un sous ensemble de l’univers. On donne quelques exemples: 1. Si l’expérience consiste à jeter une pièce de monnaie, alors \\(\\Omega=\\{P,F\\}\\). 2. Si l’expérience consiste à jeter un dé cubique dont ses faces sont numérotées de 1 à 6, alors \\(\\Omega=\\{1,2,3,4,5,6 \\}\\). Pour chaque évènement \\(E\\) de l’univers \\(\\Omega\\), on définit un nombre \\(P(E)\\) qui satisfait les axiomes suivants: Axiome 1: \\(0 \\leq P(E) \\leq 1\\); Axiome 2: \\(P(\\Omega)=1\\); Axiome 3: Pour toute séquence des évènements \\(E_1 , E_2, \\ldots , E_n\\) qui sont mutuellement exclusifs (\\(E_i \\cap E_j=\\emptyset , \\; \\forall \\; i \\neq j\\) et \\(\\displaystyle{\\bigcup\\limits_{i=1}^nE_i=\\Omega}\\)), on a \\[ P \\left(\\bigcup\\limits_{i=1}^nE_i \\right)=\\sum_{i=1}^n P(E_i) \\] Quelques conséquences de ces axiomes sont tirées: Si \\(E \\subset F\\), alors \\(P(E) \\leq P(F)\\). \\(P ( \\bar{E})=1-P(E)\\) où \\(\\bar{E}\\) est le complémentaire de \\(E\\). \\(P \\left(\\bigcup\\limits_{i=1}^nE_i \\right)=\\displaystyle\\sum_{i=1}^n P(E_i)\\), lorsque \\(E_i\\) sont mutuellement exclusifs. \\(P \\left(\\bigcup\\limits_{i=1}^nE_i \\right)\\leq\\displaystyle \\sum_{i=1}^n P(E_i)\\) (Inégalité de Boole). Exemple 1.1 L’expérience consiste à lancer une pièce de monnaie équilibrée. Donc \\(P(\\{P\\})= P(\\{F\\})=0.5\\) Exemple 1.2 On lance un dé cubique équilibré dont ses faces sont numérotées de 1 à 6. \\(P(\\{i \\})= \\dfrac{1}{6}, \\; \\forall\\, i=1,2,\\ldots,6\\). La probabilité d’obtenir un nombre pair est \\(P(\\{2,4,6\\})= P(\\{2 \\})+P(\\{4 \\}) +P(\\{6 \\}) = \\dfrac{1}{2}\\). 1.1.1 Probabilité conditionnelle Définition 1.1 Soient \\(A\\) et \\(B\\) deux évènements tels que \\(P(B)\\neq0\\). La probabilité de A sachant B est le nombre \\[ P(A|B)=\\frac{P(A \\cap B)}{P(B)} \\] Exemple 1.3 Une urne contient 10 boules numérotées de 1 à 10 indiscernables au toucher. On tire au hasard une boule. Sachant que le numéro de la boule tirée est au moins égale à 5, quelle est la probabilité qu’il soit égale à 10? Soit \\(A\\) l’évènement d’avoir une boule portant le numéro 10. Soit \\(B\\) l’évènement d’avoir une boule portant un numéro supèrieur ou égale à 5. La probabilité demandée est \\(P(A|B)\\) \\[ P(A|B)=\\frac{P(A \\cap B)}{P(B)}=\\frac{P(A)}{P(B)}=\\frac{1/10}{6/10}=1/6 \\] 1.1.2 Indépendance Définition 1.2 On dit que deux évènements, A et B, sont indépendants si \\(P(A\\cap B)=P(A)\\times P(B)\\) Si \\(A\\) et \\(B\\) deux évènements indépendants, alors \\(P(A|B)=P(A)\\) et \\(P(B|A)=P(B)\\). Exemple 1.4 On lance deux dés cubiques équilibrés numérotés de 1 à 6. Soit \\(A\\) l’événement d’obtenir une somme égale six et \\(B\\) désigne l’événement où le premier dé est égal à quatre. Vérifier que les deux évènements \\(A\\) et \\(B\\) sont indépendants. \\(P(A\\cap B)=p(\\{4,2 \\})=1/36\\) et \\(P(A)=1/6\\), \\(P(B)=1/6\\). Donc \\(P(A)\\times P(B)=1/6 \\times 1/6 =1/36 =P(A\\cap B)\\). Ainsi, les évènements \\(A\\) et \\(B\\) sont indépendants. 1.2 Variables aléatoires Définition 1.3 Soit une expérience aléatoire d’univers \\(\\Omega\\). Une variable aléatoire \\(X\\) est une application de l’ensemble \\(\\Omega\\) vers un ensemble de réalisations. Pour tout évènement \\(A\\), on \\(P(X \\in A)=P(X^{-1}(A))\\) où \\(X^{-1}(A)\\) est l’évènement comprenant tous les éléments \\(\\omega \\in \\Omega\\) tels que \\(X(\\omega) \\in A\\). La fonction de répartition \\(F\\) d’une variable aléatoire \\(X\\) est définie par \\[ F(x)=P(X \\leq x)=P(X \\in ]-\\infty, x]), \\; \\forall \\, x \\in \\mathbb{R} \\] Une variable aléatoire \\(X\\) est dite discrète si son ensemble des valeurs possibles est dénombrables. Dans ce cas, on a \\[ F(x)=\\sum_{k \\leq x }P(X=k) \\] Une variable aléatoire \\(X\\) est dite continue s’il existe une fonction \\(f(x)\\), appelée densité de probabilité, telle que \\[ P(X\\in B)=\\int_Bf(x)dx \\; \\text{ pour tout ensemble }B \\] Puisque \\(F(x)=\\displaystyle \\int_{-\\infty}^x f(x) dx\\), alors \\[ f(x)=\\frac{d}{dx}F(x) \\] La fonction de répartition jointe d’un couple aléatoire \\(X\\) et \\(Y\\) est \\(F(x,y)=P(X \\leq x, Y \\leq y)\\). Les fonctions de répartition de \\(X\\) et \\(Y\\), \\[ F_X(x)=P(X\\leq x) \\text{ et }F_Y(y)=P(Y\\leq y) \\] peuvent être déduites de \\(F(x,y)\\). En effet, \\[ F_X(x)=\\lim_{y \\longrightarrow \\infty}F(x,y) \\; \\text{ et }\\;F_Y(y)=\\lim_{x \\longrightarrow \\infty}F(x,y) \\] Les variables aléatoires \\(X\\) et \\(Y\\) sont indépendantes si \\[ F(x,y)=F_X(x) F_Y(y) \\] \\(X\\) et \\(Y\\) sont continues s’il existe une fonction \\(f(x,y)\\), dite densité de probabilité jointe, telle que \\[ P(X\\in A, Y\\in B)=\\int_A\\int_B f(x,y)dxdy\\;\\; \\forall A,B \\] La fonction de répartition d’une suite de \\(n\\) variables aléatoires \\(X_1, X_2, \\ldots, X_n\\) est définie par: \\[ F(X_1, X_2, \\ldots, X_n)=P(X_1\\leq x_1, X_2\\leq x_2, \\ldots, X_n \\leq x_n) \\] et sont indépendantes si \\[ F(X_1, X_2, \\ldots, X_n)=F_{X_1}(x_1)F_{X_2}(x_2)\\ldots F_{X_n}(x_n) \\] 1.3 Espérance mathématique Définition 1.4 L’espérance mathématique ou moyenne d’une variavle aléatoire \\(X\\), notée \\(\\mathbb{E}(X)\\), est définie par: \\[\\begin{align*} \\mathbb{E}(X) &amp; = \\int_{\\mathbb{R}}x dF(x)\\\\ &amp; = \\begin{cases} \\displaystyle \\sum_x xP(X=x)\\; \\text{si }X \\text{ est discrète}\\\\ \\displaystyle \\int_{\\mathbb{R}} xf(x)dx \\; \\text{si }X \\text{ est continue} \\end{cases} \\end{align*}\\] De même, on définit l’espérance d’une fonction de \\(X\\), \\(g(X)\\), par: \\[ \\mathbb{E}\\left[ g(X)\\right]=\\int_{\\mathbb{R}}x dF_g(x)=\\int_{\\mathbb{R}}g(x) dF(x) \\] L’espérance d’une somme de variables aléatoires est la somme des espérances: \\[ \\mathbb{E}\\left[\\sum_{i=1}^n X_i \\right]=\\sum_{i=1}^n\\mathbb{E}(X_i) \\] La variance d’une variable aléatoire, \\(X\\), est définie par \\[ \\mathbb{V}(X)=\\mathbb{E}\\left[{(X-\\mathbb{E}(X))}^2 \\right]=\\mathbb{E}(X^2)-{\\mathbb{E}(X)}^2 \\] Deux variables aléatoires, \\(X\\) et \\(Y\\), sont dites non corréllées si leur covariance, définie par: \\[ \\text{Cov}(X,Y)=\\mathbb{E}\\left[(X-\\mathbb{E}(X))(Y-\\mathbb{E}(Y))\\right]=\\mathbb{E}(XY)-\\mathbb{E}(X)\\mathbb{E}(Y) \\] est nulle. Noter que si \\(X\\) et \\(Y\\) sont indépendantes, alors elles sont non corréllées (\\(\\text{Cov}(X,Y)=0\\)). Propriétés de la covariance Pour toutes variables aléatoires \\(X, Y, Z\\) et \\(a \\in \\mathbb{R}\\), on a: 1. Cov\\((X,X)=\\mathbb{V}(X)\\) et Cov\\((X,Y)=\\) Cov$(Y,X) $ 2. Cov\\((aX,Y)=a\\)Cov\\((X,Y)\\). 3. Cov\\((X,Y+Z)=\\) Cov\\((X,Y)+\\) Cov\\((X,Z)\\). Une généralisation de la troisième propriétés est donnée par: \\[ \\text{Cov}\\left( \\sum_{i=1}^nX_i,\\sum_{j=1}^m Y_i \\right)=\\sum_{i=1}^n \\sum_{j=1}^m \\text{Cov}(X_i,Y_j) \\] Une expression utile pour la variance de la somme des variables aléatoires peut être déduite comme suit: \\[\\begin{align*} \\mathbb{V}\\left(\\sum_{i=1}^nX_i \\right)&amp; =\\text{Cov}\\left(\\sum_{i=1}^nX_i,\\sum_{i=1}^nX_i\\right)\\\\ &amp;=\\sum_{i=1}^n \\sum_{j=1}^n\\text{Cov}(X_i,X_j)\\\\ &amp;=\\sum_{i=1}^n\\text{Cov}(X_i,X_i)+\\sum_{i=1}^n\\sum_{i\\neq j}\\text{Cov}(X_i,X_j)\\\\ &amp;=\\sum_{i=1}^n\\mathbb{V}(X_i)+2\\sum_{i=1}^n\\sum_{j &lt;i} \\text{Cov}(X_i,X_j) \\end{align*}\\] Définition 1.5 Si \\(X_1,X_2,\\ldots, X_n\\) sont indépendantes et identiquement distribuées, noté \\(X_i \\sim iid\\), d’espérance \\(m\\) et de variance \\(\\sigma^2\\), alors: \\(\\overline{X}=\\displaystyle \\frac{1}{n}\\sum_{i=1}^n X_i\\) est appelée moyenne empirique. \\(\\mathbb{E}(\\overline{X})=m\\) et \\(\\mathbb{V}(\\overline{X})=\\displaystyle \\frac{\\sigma^2}{n}\\). Cov\\((\\overline{X},X_i-\\overline{X})=0,\\) \\(i=1,2,\\ldots,n\\). Exemple 1.5 Calculer la variance d’une variable aléatoire \\(X\\) suivant une loi binomiale de paramètres \\(n\\) et \\(p\\). Puisqu’une telle variable aléatoire représente le nombre de succès dans \\(n\\) essais indépendants lorsque chaque essai a une probabilité commune p d’être un succès, nous pouvons écrire \\[ X=X_1+X_2+\\ldots+X_n \\] où \\(X_i \\stackrel{iid}{\\sim}B(p)\\) telle que \\[ X_i=\\begin{cases} 1 \\text{ si le ième issue est un succés}\\\\ 0 \\text{ sinon} \\end{cases} \\] Par conséquent, on aura \\(\\mathbb{V}(X)=\\displaystyle \\sum_{i=1}^n\\mathbb{V}(X_i)\\), Or \\[\\begin{align*} \\mathbb{V}(X_i)&amp;=\\mathbb{E}(X_i^2)-{\\mathbb{E}(X_i)}^2\\\\ &amp;=\\mathbb{E}(X_i)-{\\mathbb{E}(X_i)}^2 \\text{ car } X_i^2=X_i\\\\ &amp;= p-p^2= p(1-p) \\end{align*}\\] Donc \\(\\mathbb{V}(X)=np(1-p)\\). 1.4 Fonctions génératrices des moments Définition 1.6 La fonction génératrice des moments \\(\\phi(t)\\) de la variable aléatoire \\(X\\) est définie pour tout \\(t \\in \\mathbb{R}\\) par \\[\\begin{align*} \\phi(t)&amp;=\\mathbb{E}\\left[e^{tX} \\right]\\\\ &amp;= \\begin{cases} \\displaystyle \\sum_x e^{tx}P(X=x)\\text{ si } X \\text{ est discrète}\\\\ \\displaystyle \\int_{\\mathbb{R}}e^{tx} f(x)dx \\text{ si } X \\text{ est continue} \\end{cases} \\end{align*}\\] \\(\\phi(t)\\) est appelée fonction génératrice des moments car tous les moments de \\(X\\) peuvent être obtenues par les dérivées successives de \\(\\phi(t)\\). Par exemple \\[\\begin{align*} \\phi&#39;(t)&amp;=\\dfrac{d}{dt}\\mathbb{E}\\left[e^{tX} \\right] \\\\ &amp;=\\mathbb{E}\\left[\\dfrac{d}{dt}(e^{tX}) \\right]=\\mathbb{E}\\left[Xe^{tX} \\right] \\end{align*}\\] Par conséquent \\(\\phi&#39;(0)= \\mathbb{E}(X)\\). D’une manière plus générale, \\(\\phi^n(0)=\\mathbb{E}\\left( {X}^n\\right),\\; n \\geq 1\\). Une propriété importante des fonctions génératrices des moments est que la fonction génératrice des moments de la somme des variables aléatoires indépendantes est simplement le produit des fonctions génératrices des moments individuelles. Pour voir cela, supposons que \\(X\\) et \\(Y\\) sont indépendantes et ont respectivement des fonctions génératrices des moments \\(\\phi_X(t)\\) et \\(\\phi_Y(t)\\). Alors la fonction génératrice des moments de \\(X+Y\\) est donnée par: \\[\\begin{align*} \\phi_{X+Y}(t)&amp;=\\mathbb{E}\\left(e^{t(X+Y)} \\right)=\\mathbb{E}\\left(e^{tX}e^{tY)} \\right)\\\\ &amp;=\\mathbb{E}\\left(e^{tX}\\right) \\mathbb{E}\\left(e^{tY}\\right)=\\phi_X(t)\\phi_Y(t) \\end{align*}\\] Exemple 1.6 (Loi Binomiale de paramètres n et p) \\[\\begin{align*} \\phi(t)&amp;=\\mathbb{E}\\left[e^{tX} \\right]=\\sum_{k=0}^ne^{tk}C^n_kp^k{(1-p)}^{n-k}\\\\ &amp;=\\sum_{k=0}^nC^n_k{\\left(pe^t\\right)}^k{(1-p)}^{n-k} \\end{align*}\\] Or, d’après la formule de Binôme, on a \\[ {(a+b)}^n=\\sum_{k=0}^nC_n^ka^kb^{n-k} \\] d’où \\(\\phi(t)={\\left( pe^t+(1-p)\\right)}^n\\) et par conséquent \\[ \\phi&#39;(t)=n{\\left(pe^t+1-p \\right)}^{n-1}pe^t \\] D’où \\(\\mathbb{E}(X)=\\phi&#39;(0)=np\\). Dérivons une deuxième fois la fonction \\(\\phi(t)\\), on obtient \\[ \\phi&#39;&#39;(t)=n(n-1){\\left(pe^t+1-p \\right)}^{n-2}{\\left(pe^t\\right)}^2+n{\\left(pe^t+1-p \\right)}^{n-1}pe^t \\] En déduit, alors \\[ \\mathbb{E}(X^2)=\\phi&#39;&#39;(0)=n(n-1)p^2+np \\] Donc, on peut déduire la variance de \\(X\\). \\[ \\mathbb{V}(X)=\\mathbb{E}(X^2)-\\mathbb{E}{(X)}^2=\\phi&#39;&#39;(0)-{\\left( \\phi&#39;(0)\\right)}^2=np(1-p) \\] Exemple 1.7 (Loi Normale standard) \\[\\begin{align*} \\mathbb{E}\\left(e^{tX} \\right)&amp;=\\dfrac{1}{\\sqrt{2\\pi}}\\int_{\\mathbb{R}}e^{tx-x^2/2}dx\\\\ &amp;=\\dfrac{1}{\\sqrt{2\\pi}}\\int_{\\mathbb{R}}e^{-(x^2-2tx)/2}dx\\\\ &amp;=e^{t^2/2}\\dfrac{1}{\\sqrt{2\\pi}}\\int_{\\mathbb{R}}e^{-(x-t)^2/2}dx\\\\ &amp;= e^{t^2/2} \\end{align*}\\] Si \\(Y \\sim N(m,\\sigma^2)\\), alors \\[ \\phi_Y(t)=\\mathbb{E}\\left[e^{t(\\sigma X+m)} \\right]=\\exp\\left[\\dfrac{\\sigma^2t^2}{2}+m \\right] \\] Sous R, on peut déterminer et évaluer les fonctions génératrices des moments en utilisant l’extension MGF qui est téléchargeable depuis l’adresse suivante: https://github.com/alexandernel14/MGF. Une description de l’installation et l’utilisation de cette extension est donnée comme suit: # installer &#39;devtools&#39;: install.packages(&quot;devtools&quot;) # installer &#39;MGF&#39; depuis github #devtools::install_github(&quot;alexandernel14/MGF&quot;,force = T) # charger l&#39;extension &#39;MGF&#39; library(MGF) # fonction génératrice de la loi binomiale mgf(&quot;Binomial&quot;) [1] &quot;(1-p+p*exp(t))^n&quot; # t=0, ordre 1 MGF_evaluator(&quot;Binomial&quot;,t=0, order_of_moment=1, n=10, p=0.4) The Moment Generating Function for the Binomial distribution is: [1] &quot;(1-p+p*exp(t))^n&quot; The formula for the 1st moment is: (1 - p + p * exp(t))^(n - 1) * (n * (p * exp(t))) The value of the 1st moment is: [1] 4 The formula of the 1st centralized moment is: (1 - p + p * exp(t))^(n - 1) * (n * (p * exp(t)))/(1 - p + p * exp(t))^n The 1st centralized moment&#39;s value is: [1] 4 # t=0, ordre 2 MGF_evaluator(&quot;Binomial&quot;,t=0, order_of_moment=2, n=10, p=0.4) The Moment Generating Function for the Binomial distribution is: [1] &quot;(1-p+p*exp(t))^n&quot; The formula for the 2nd moment is: (1 - p + p * exp(t))^((n - 1) - 1) * ((n - 1) * (p * exp(t))) * (n * (p * exp(t))) + (1 - p + p * exp(t))^(n - 1) * (n * (p * exp(t))) The value of the 2nd moment is: [1] 18.4 The formula of the 2nd centralized moment is: ((1 - p + p * exp(t))^((n - 1) - 1) * ((n - 1) * (p * exp(t))) * (n * (p * exp(t))) + (1 - p + p * exp(t))^(n - 1) * (n * (p * exp(t))))/(1 - p + p * exp(t))^n - (1 - p + p * exp(t))^(n - 1) * (n * (p * exp(t))) * ((1 - p + p * exp(t))^(n - 1) * (n * (p * exp(t))))/((1 - p + p * exp(t))^n)^2 The 2nd centralized moment&#39;s value is: [1] 2.4 # fonction génératrice de la loi normale mgf(&quot;Normal&quot;) [1] &quot;exp(mu*t + 0.5*sigma^2*t^2)&quot; # t=0, ordre 1 MGF_evaluator(&quot;Normal&quot;,t=0, order_of_moment=1) The Moment Generating Function for the Normal distribution is: [1] &quot;exp(mu*t + 0.5*sigma^2*t^2)&quot; The formula for the 1st moment is: exp(mu * t + 0.5 * sigma^2 * t^2) * (mu + 0.5 * sigma^2 * (2 * t)) The value of the 1st moment is: [1] 0 The formula of the 1st centralized moment is: mu + 0.5 * sigma^2 * (2 * t) The 1st centralized moment&#39;s value is: [1] 0 # t=0, ordre 2 MGF_evaluator(&quot;Normal&quot;,t=0, order_of_moment=2) The Moment Generating Function for the Normal distribution is: [1] &quot;exp(mu*t + 0.5*sigma^2*t^2)&quot; The formula for the 2nd moment is: exp(mu * t + 0.5 * sigma^2 * t^2) * (mu + 0.5 * sigma^2 * (2 * t)) * (mu + 0.5 * sigma^2 * (2 * t)) + exp(mu * t + 0.5 * sigma^2 * t^2) * (0.5 * sigma^2 * 2) The value of the 2nd moment is: [1] 1 The formula of the 2nd centralized moment is: 0.5 * sigma^2 * 2 The 2nd centralized moment&#39;s value is: [1] 1 1.5 Fonctions caractéristiques Il existe des variables aléatoires pour lesquelles la fonction génératrice des moments n’existe pas. Dans ce cas, on peut faire recours à la fonction caractéristique définie ci-dessous. Définition 1.7 La fonction caractéristique d’une variable aléatoire \\(X\\) est la fonction à valeurs complexes définie sur \\(\\mathbb {R}\\) par \\[\\begin{align*}\\psi_{X}(t)&amp;=\\mathbb{E} \\left[{e} ^{\\mathrm{i} tX}\\right]\\\\ &amp;=\\begin{cases} \\displaystyle \\sum_{i=1}^n {e} ^{\\mathrm{i} tX }P(X=x_i) \\text{ si } X \\text{ est discrète}\\\\ \\displaystyle \\int_{\\mathbb{R} }e^{\\mathrm{i} tx} f(x)\\,\\mathrm{d} x \\text{ si } X \\text{ est continue} \\end{cases} \\end{align*}\\] où \\(\\mathrm{i}=\\sqrt{-1}\\). Proposition 1.1 Soit \\(X\\) une variable aléatoire, \\(a\\) et \\(b\\) deux réels. Alors les propriétés suivantes sont toujours vraies : 1. Pour tout \\(t \\in \\mathbb{R}\\), \\(\\left|\\psi_X(t)\\right| \\leq 1\\). 2. \\(\\psi_X(0)=1\\). 3. Pour tout \\(t \\in \\mathbb{R}\\), \\(\\psi_X(−t) = \\overline{\\psi_X(t)}\\). 4. Pour tout \\(t \\in \\mathbb{R}\\), \\(\\psi_{aX+b}(t) = e^{\\mathrm{i}tb} \\psi_X(at)\\). 5. \\(\\psi_X(t)\\) est continue sur \\(\\mathbb{R}\\). Proposition 1.2 Si le moment d’ordre \\(n\\) d’une variable aléatoire \\(X\\) existe, alors la fonction caractéristique de \\(X\\) est \\(n\\) fois dérivable et : \\[ \\mathbb{E}\\left({X}^n \\right)=\\dfrac{1}{{\\mathrm{i}}^n}{\\psi}^n(0) \\] Exemple 1.8 (Loi normal standard) La fonction caractéristique de la loi normale standard est: \\[\\psi(t)={e}^{-t^2/2}\\] Exemple 1.9 (Loi exponentielle) La fonction caractéristique de la loi exponentielle de paramètre \\(\\lambda\\) est: \\[ \\psi(t)=\\dfrac{\\lambda}{\\mathrm{i}t-\\lambda} \\] Si \\(X_1,X_2,\\ldots , X_n\\) sont des variables indépendantes, alors \\[ \\psi_{\\sum_iX_i}(t)=\\prod_i\\psi_{X_i}(t) \\] 1.6 Espérance conditionnelle - Variance conditionnelle L’un des concepts les plus utiles de la théorie des probabilités est celui de la probabilité conditionnelle et de l’espérance conditionnelle. La raison est double. Premièrement, dans la pratique, nous nous intéressons souvent au calcul des probabilités et des espérances lorsqu’une information partielle est disponible; par conséquent, les probabilités et les espérances souhaitées sont conditionnelles. Deuxièmement, pour calculer une probabilité , il est souvent extrêmement utile d’abord conditionner une variable aléatoire appropriée. 1.6.1 Densité conditionnelle Soient \\(X\\) et \\(Y\\) deux variables aléatoires de densité jointe \\(f(x,y)\\). Définition 1.8 On définit la densité conditionnelle de \\(X\\) sachant \\(Y=y\\) par: \\[ f_{X|Y}(x,y)=\\begin{cases} \\dfrac{P(X=x,Y=y)}{P_Y(Y=y)} \\text{ si } X \\text{ et } Y \\text{ sont discrètes}\\\\ \\dfrac{f(x,y)}{f_Y(y)}\\text{ si } X \\text{ et } Y \\text{ sont continues} \\end{cases} \\] Exemple 1.10 Soit un couple aléatoire discrète \\((X,Y)\\) définie par la densité jointe suivante: \\[ P(X=1,Y=1)=0.5;\\,P(X=1,Y=2)=0.1;\\,P(X=2,Y=1)=0.1;\\,P(X=2,Y=2)=0.3 \\] Déterminer la loi conditionnelle \\(f_{X|Y=1}(x,y)\\). La densité conditionnelle est par définition \\[ {f}_{X|Y=1}(x,y)=\\dfrac{P(X=x,Y=1)}{{P}_Y(Y=1)} \\] Or, \\(P_y(Y=1)=\\displaystyle \\sum_x P(X=x,Y=1)=p(1,1)+p(2,1)=0.6\\). D’où \\[ {f}_{X|Y=1}(1,1)=\\dfrac{P(X=1,Y=1)}{{P}_Y(Y=1)}=\\dfrac{p(1,1)}{{P}_Y(1)}=\\dfrac{5}{6} \\] \\[ {f}_{X|Y=1}(2,1)=\\dfrac{P(X=2,Y=1)}{{P}_Y(Y=1)}=\\dfrac{p(2,1)}{{P}_Y(1)}=\\dfrac{1}{6} \\] 1.6.2 Espérance conditionnelle Une espérance conditionnelle est une expression calculée depuis une distribution conditionnelle. On écrit \\(\\mathbb{E}\\left(Y|X=x \\right)\\) pour l’espérance de \\(Y\\) sachant \\(X=x\\). Définition 1.9 L’espérance conditionnelle de \\(Y\\) sachant \\(X=x\\) est \\[ \\mathbb{E}\\left(Y|X=x \\right)=\\left\\{ \\begin{array}{ll} \\displaystyle \\sum_y y\\mathbb{P}\\left(Y=y|X=x \\right) &amp; \\text{ cas discret}\\\\ \\displaystyle \\int_{\\mathbb{R}}yf_{Y|X}(x,y)dy &amp; \\text{ cas continu} \\end{array} \\right. \\] Exemple 1.11 On donne \\(Y=\\begin{cases} 1 \\text{ avec une probabilité }\\frac{1}{8}\\\\ 2 \\text{ avec une probabilité }\\frac{7}{8} \\end{cases}\\) et \\(X|Y=\\begin{cases} 2Y \\text{ avec une probabilité }\\frac{3}{4}\\\\ 3Y \\text{ avec une probabilité }\\frac{1}{4} \\end{cases}\\) Déterminer \\(\\mathbb{E}\\left( X|Y=y\\right)\\). Si \\(Y=\\), alors \\(\\left(X|Y= \\right)= \\begin{cases} 2 \\text{ avec une probabilité }\\frac{3}{4}\\\\ 3 \\text{ avec une probabilité }\\frac{1}{4} \\end{cases}\\) D’où \\(\\mathbb{E}\\left( X|Y=1\\right)=\\displaystyle \\sum_x x\\mathbb{P}\\left( X|Y=1\\right)=2\\times\\frac{3}{4}+3\\times \\frac{1}{4}=\\frac{9}{4}\\). Si \\(Y=2\\), alors \\(\\left(X|Y=2 \\right)= \\begin{cases} 4 \\text{ avec une probabilité }\\frac{3}{4}\\\\ 6 \\text{ avec une probabilité }\\frac{1}{4} \\end{cases}\\) D’où \\(\\mathbb{E}\\left( X|Y=2\\right)=\\displaystyle \\sum_x x\\mathbb{P}\\left( X|Y=2\\right)=4\\times\\frac{3}{4}+6\\times \\frac{1}{4}=\\frac{18}{4}\\). Donc \\(\\mathbb{E}\\left( X|Y=y\\right)= \\begin{cases} \\frac{9}{4} \\text{ si }Y=1 \\text{ avec une prob} =\\frac{1}{8}\\\\ \\frac{18}{4} \\text{ si } Y=2 \\text{ avec une prob }=\\frac{7}{8} \\end{cases}\\). Exemple 1.12 Soit la densité jointe d’un couple aléatoire définie par: \\[f(x,y)=\\frac{2}{xy},\\; \\text{ pour }\\;1&lt;y&lt;x&lt;e \\] Déterminer \\(\\mathbb{E}\\left( Y|X=x\\right)\\) Par définition \\(\\mathbb{E}\\left( Y|X=x\\right)=\\displaystyle \\int_{\\mathbb{R}}y{f}_{X|Y}(x,y)dy\\). Or \\({f}_{X|Y}(x,y)=\\dfrac{f(x,y)}{{f}_X(x)}\\) avec \\[\\begin{align*} {f}_X(x)=&amp;\\int_1^x\\dfrac{2}{xy}dy=\\dfrac{2}{x}\\biggl[\\ln(y) \\biggr]_1^x\\\\ =&amp;\\dfrac{2\\ln(x)}{x},\\;\\text{ pour }\\; 1&lt;x&lt;e. \\end{align*}\\] D’où \\({f}_{X|Y}(x,y)=\\dfrac{2}{xy}\\dfrac{x}{\\ln(x)}=\\dfrac{1}{y\\ln(x)}\\) pour \\(1&lt;y&lt;x\\), et par conséquent, \\[ \\mathbb{E}\\left( Y|X=x\\right)=\\int_1^x \\dfrac{y}{y\\ln(x)}dy=\\dfrac{1}{\\ln(x)}\\biggl[ y\\biggr]_1^x=\\dfrac{x-1}{\\ln(x)} \\] Propriétés de l’espérance conditionnelle 1. Linéarité: Pour toutes constantes \\(a,b\\) et \\(X,Y\\) et \\(Z\\) des variables aléatoires, \\[\\mathbb{E}\\left(aY+bZ|X=x\\right)=a \\mathbb{E}\\left(Y|X=x\\right)+b\\mathbb{E}\\left(Z|X=x\\right)\\] 2. Indépendance: Si \\(X\\) et \\(Y\\) sont deux variables aléatoires indépendantes, alors \\(\\mathbb{E}\\left(Y|X=x\\right)=\\mathbb{E}\\left(Y\\right)\\) 3. \\(\\mathbb{E}\\left(g(X)|X=x\\right)=\\mathbb{E}\\left(X\\right)\\) où \\(g\\) est une transformation. 4. Espérance totale: \\(\\mathbb{E}\\left(Y\\right)=\\mathbb{E}\\bigl(\\mathbb{E}\\left(Y|X=x\\right)\\bigr)\\): La moyenne totale est la moyenne des moyennes. Exemple 1.13 Reprenons l’exemple 1.11. \\(\\mathbb{E}\\left( X|Y=y\\right)= \\begin{cases} \\frac{9}{4} \\text{ avec une prob } =\\frac{1}{8}\\\\ \\frac{18}{4} \\text{ avec une prob }=\\frac{7}{8} \\end{cases}\\). Donc, l’espérance totale est: \\(\\mathbb{E}\\left(X\\right)= \\frac{9}{4} \\times \\frac{1}{8} + \\frac{18}{4} \\times \\frac{7}{8} = \\frac{135}{32}\\) Exercice 1.1 On jette une pièce de monnaie équilibrée. Soit \\(Y\\) la variable aléatoire désignant le nombre des lancers avant d’obtenir Face pour la première fois. Déterminer la loi de \\(Y\\) ainsi que son espérance et sa variance. Simuler 10 000 réalisations de \\(Y\\). Soit \\(\\left(X|Y=y\\right)\\sim \\mathcal{P}(\\lambda Y)\\). Calculer \\(\\mathbb{E}\\left(X|Y=y\\right)\\) et \\(\\mathbb{E}\\left(X\\right)\\). En prenant \\(\\lambda=2\\) et à l’aide des simulations, donner la valeur de \\(\\mathbb{E}\\left(X|Y=y\\right)\\). Solution 1. Soit \\(P(F)=p\\) et \\(P(P)=1-p\\). On a \\((n-1)\\) premières épreuves donnant \\(P\\) et la nième épreuve donne \\(F\\), et puisque les épreuves sont indépendantes, alors \\[ \\mathbb{P}\\bigl(Y=n \\bigr)={(1-p)}^{n}p\\;,\\;\\; n=0,1,2,\\ldots \\] Donc \\(Y\\sim G(p)\\). Soit \\(Z=(X|Y=y)\\sim \\mathcal{P}(\\lambda Y)\\), \\(\\mathbb{E}\\left(Z\\right)=\\mathbb{E}\\left(X|Y=y\\right)= \\lambda Y\\). \\[\\begin{align*} \\mathbb{E}\\left(X\\right)&amp;=\\mathbb{E}\\bigl(\\mathbb{E}\\left(X|Y=y\\right)\\bigr)=\\mathbb{E}(\\lambda Y)\\\\ &amp;= \\lambda \\mathbb{E}(Y)=\\lambda \\dfrac{1-p}{p} \\end{align*}\\] set.seed(1) y=rgeom(10000, prob=0.5) set.seed(1) x=rpois(10000,lambda = 2*y) mean(x) [1] 2.0029 La figure suivante donne l’évolution de \\(\\mathbb{E}\\left(X|Y=y\\right)\\) en fonction du nombre des simulations. 1.6.3 Variance conditionnelle Similairement à l’espérance conditionnelle, la variance conditionnelle est une variance prise par rapport à une distribution conditionnelle. Étant donné les variables aléatoires \\(X\\) et \\(Y\\), soit \\(m_X=\\mathbb{E}\\left(Y|X=x \\right)\\). La variance conditionnelle \\(\\mathbb{V}(Y | X = x)\\)est définie comme suit: Définition 1.10 La variance conditionnelle de \\(Y\\) sachant \\(X=x\\) est \\[ \\mathbb{V}\\left(Y|X=x \\right)=\\left\\{ \\begin{array}{ll} \\displaystyle \\sum_y (y-m_X)\\mathbb{P}\\left(Y=y|X=x \\right) &amp; \\text{ cas discret}\\\\ \\displaystyle \\int_{\\mathbb{R}}(y-m_X)^2f_{Y|X}(x,y)dy &amp; \\text{ cas continu} \\end{array} \\right. \\] La variance conditinnelle possède les propriétés suivantes: Propriétes de la variance conditionnelle 1. \\(\\mathbb{V}\\left(Y|X=x \\right)=\\mathbb{E}\\left(Y^2|X=x \\right)-\\mathbb{E}\\left(Y|X=x \\right)^2\\). 2. \\(\\mathbb{V}(aY + b|X = x) = a^2\\mathbb{V}(Y|X = x)\\). 3. Variance totale: \\(\\mathbb{V}(Y) = \\mathbb{E}\\bigl(\\mathbb{V}(Y|X)\\bigr) + \\mathbb{V}\\bigl(\\mathbb{E}(Y|X)\\bigr)\\). Exemple 1.14 Soit \\(X\\) une variable aléatoire uniforme sur \\(]0,1[\\). Si \\(X=x\\), alors \\(Y\\) suit une loi uniforme sur \\(]0,x[\\). Déterminer la variance de \\(Y\\). La distribution conditionnelle de \\(Y|X=x\\) est uniforme sur \\(]0,x[\\). On déduit alors, \\[\\mathbb{E}(Y|X = x) = \\dfrac{x}{2} \\; \\text{ et }\\; \\mathbb{V}(Y|X = x) = \\dfrac{x^2}{12}\\] La propriété de la variance totale donne, \\[\\begin{align*}\\mathbb{V}(Y) &amp;= \\mathbb{E}(\\mathbb{V}(Y|X)) + \\mathbb{V}(\\mathbb{E}(Y|X)) = \\mathbb{E} \\left(\\frac{X^2}{12}\\right) + \\mathbb{V}\\left(\\frac{X}{2} \\right)\\qquad \\qquad \\\\ &amp;=\\frac{1}{12}\\mathbb{E} \\left(X^2\\right)+\\frac{1}{4}\\mathbb{V}\\left(X\\right)=\\frac{1}{12}\\times \\frac{1}{3}+\\frac{1}{4}\\times \\frac{1}{12}=\\frac{7}{144}=0.04861. \\end{align*}\\] Sous R, on peut procéder comme suit: set.seed(1) x=runif(10000,0,1) # réalisations uniformes sur ]0,1[ y=runif(10000,0,x) # réalisations uniformes sur ]0,x[ var(y) [1] 0.04906725 L’évolution de la variance conditionnelle suivant le nombre des simulations est donnée par le graphique suivant: 1.6.4 Théorèmes limites Théoreme 1.1 (Loi forte des grands nombres) Si \\(X_1,X_2,\\ldots, X_n\\) sont des variables aléatoires \\(iid\\) de moyenne \\(m\\), alors \\[ \\mathbb{P}\\left[\\lim_{n \\rightarrow \\infty}\\overline{X}_n=m \\right]=1 \\] La moyenne des \\(n\\) premiers termes d’une suite de variables aléatoires \\(iid\\) converge presque sûrement vers l’espérance mathématique \\(\\mathbb{E}(X_i)=m\\), lorsque \\(n\\) tend vers l’infini. Vérifions ce théorème à l’aide des simulations. On considère l’expérience suivante: On lance une pièce de monnaie équilibrée \\(n\\) fois. Soit \\(X_i=1\\) si Face et \\(X_i=0\\) si Pile. D’après la loi des grands nombres, \\(\\overline{X}_n\\) converge vers \\(\\mathbb{E}(X_i)=p=0.5\\). set.seed(1) s=sample(c(0,1),10000, replace = T) x_bar=cumsum(s)/(1:10000) plot(x_bar, type=&quot;l&quot;,col=&quot;blue&quot;, xlab=&quot;Nombre de simulations&quot;, ylab=&quot;&quot;) abline(h=0.5, col=&quot;red&quot;, lwd=2) legend(&quot;bottomright&quot;, legend=c(expression(bar(X)),expression(p==0.5)), lty=1,col=c(&quot;blue&quot;,&quot;red&quot;),bty=&quot;n&quot;) Théoreme 1.2 (Loi faible des grands nombres) Si \\(X_1,X_2,\\ldots, X_n\\) sont des variables aléatoires \\(iid\\) de moyenne \\(m\\), alors \\[ \\lim_{n \\rightarrow \\infty}\\mathbb{P}\\left[|\\overline{X}_n-m| &lt; \\epsilon \\right]=1, \\;\\; \\forall \\, \\epsilon &gt; 0 \\] Théoreme 1.3 (Théorème central limite) Si \\(X_1,X_2,\\ldots, X_n\\) sont des variables aléatoires \\(iid(m,\\sigma^2)\\), alors \\[ \\lim_{n \\rightarrow \\infty}\\mathbb{P}\\left[\\frac{\\overline{X}_n-m}{\\sigma/\\sqrt{n}} &lt; t \\right]=\\mathbb{P}(Z &lt;), \\;\\; \\text{ avec } \\; Z \\sim N(0,1) \\] Illustration sous R Soit \\(X_1, X_2,\\ldots, X_{100}\\) une suite de variables aléatoires telle que \\(X_i \\stackrel{iid}{\\sim}\\mathcal{P(\\lambda=4)}\\). On sait que \\(\\mathbb{E}(X_i)=\\mathbb{V}(X_i)=\\lambda=4\\). Simuler \\(100\\) réalisations du Poisson de paramètre \\(\\lambda=4\\) puis déduire la variable de \\(z\\) \\[z=\\dfrac{\\overline{X}-m}{\\sigma/\\sqrt{n}} \\] Répéter \\(100000\\) fois les instructions précédentes et stocker le résultat dans un objet que l’on appelle mu. Représenter l’histogramme de mu. Ajouter sur le même graphique la courbe de la densité de la loi normale standard. # 1 set.seed(1) simPois=rpois(n=100, lambda=4) z=(mean(simPois)-4)/(2/sqrt(100)) # 2 Z=function(){ simPois=rpois(n=100, lambda=4) (mean(simPois)-4)/(2/sqrt(100)) } set.seed(1) mu=replicate(100000, Z()) # 3 hist(mu,freq = F, main=&quot;&quot;) curve(dnorm,-4,4,add=T,col=4,lwd=2) 1.7 Processus stochastique Un processus stochastique est simplement une collection de variables aléatoires \\(\\{X_t, t \\in I\\}\\). L’indice \\(t\\) représente souvent le temps et l’ensemble \\(I\\) est l’ensemble d’indices du processus appelé aussi espace de temps. Les ensembles d’indices les plus courants sont \\(I = \\{0, 1, 2,\\ldots\\}\\), représentant le temps discret, et \\(I = [0, +\\infty[\\), représentant le temps continu. Les processus stochastiques en temps discret sont des séquences de variables aléatoires. Les processus en temps continu sont des collections non dénombrables de variables aléatoires. Les variables aléatoires d’un processus stochastique prennent des valeurs dans un espace d’états commun \\(E\\), discret ou continu. Un processus stochastique est spécifié par ses espaces de temps et d’état, et par les relations de dépendance entre ses variables aléatoires. Exercices Exercice 1 Pour chacune des variables aléatoires suivantes, déterminer la fonction génératrices des moments et déduire son espérance et sa variance. \\(X\\) est de densité de probabilité définie par: \\(\\mathbb{P}(X=1)=\\frac{1}{3}\\) et \\(\\mathbb{P}(X=2)=\\frac{2}{3}\\). \\(Y \\sim \\mathcal{U}[0,1]\\). Exercice 2 Déterminer \\(\\mathbb{E}\\left(X|Y=y \\right)\\) lorsque la densité jointe du couple \\((X,Y)\\) est: \\(\\displaystyle f(x,y)=\\frac{y^2-x^2}{8}e^{-x},\\;\\; 0 &lt; y &lt; \\infty\\, , \\;\\; -y&lt;x&lt;y.\\) \\(\\displaystyle f(x,y)=\\frac{e^{-x/y} e^{-y}}{y},\\;\\; 0 &lt; x &lt; \\infty\\, , \\;\\; 0&lt;y&lt;\\infty.\\) Exercice 3 Les habitants de Sousse retirent de l’argent d’un distributeur de billets selon la fonction de probabilité suivante: \\(x_i\\) en DT 100 200 500 \\(\\mathbb{P}(X=x_i)\\) 0.25 0.55 0.2 Le nombre des clients par jour, \\(N\\), suit une distribution de poisson de paramètre \\(\\lambda = 0.5\\), i.e. \\(N \\sim \\mathcal{P}(0.5)\\). Soit \\(S_N=X_1+X_2+\\ldots +X_N\\) le montant d’argent total retiré par jour, où les \\(X_i\\) sont indépentantes entre eux et avec la variable \\(N\\). Calculer \\(\\mathbb{E}(X)\\) et \\(\\mathbb{V}(X)\\). Déterminer \\(\\mathbb{E}(S_N)\\) et \\(\\mathbb{V}(S_N)\\). Reprendre les questions précédentes en utilisants des simulations sous R. Exercice 4 Soit \\(X_1, X_2,\\ldots, X_{100}\\) une suite de variables aléatoires telle que \\(X_i \\stackrel{iid}{\\sim}\\mathcal{E(\\lambda=4)}\\). On sait que \\(\\mathbb{E}(X_i)=\\frac{1}{\\lambda}\\) et \\(\\mathbb{V}(X_i)=\\frac{1}{\\lambda^2}\\). Simuler \\(100\\) réalisations de la loi exponentielle de paramètre \\(\\lambda=4\\) (rexp()) puis déduire la variable de \\(z\\) \\[z=\\dfrac{\\overline{X}-m}{\\sigma/\\sqrt{n}} \\] Répéter \\(100000\\) fois les instructions précédentes et stocker le résultat dans un objet que l’on appelle mu. Représenter l’histogramme de mu. Ajouter sur le même graphique la courbe de la densité de la loi normale standard. Exercice 5 On lance un dé équilibré, puis une pièce de monnaie équilibrée un nombre de fois égal au résultat du dé. Soit \\(X\\) le résultat du dé et \\(Y\\) le nombre de Pile amenés par la pièce de monnaie. Déterminer la loi jointe du couple \\((X, Y )\\). Soit \\(n \\in \\{1, \\ldots, 6\\}\\). Quelle est la loi de \\(Y\\) sachant \\(X = n\\) ? En déduire \\(\\mathbb{E}\\bigl[Y |X = n\\bigr]\\), puis \\(\\mathbb{E}\\bigl[Y |X\\bigr]\\). Calculer \\(E[Y]\\). Reprendre les questions 2 à 4 à l’aide des simulations sous R. Exercice 6 Le temps que Sarra passe à parler au téléphone suit une distribution exponentielle de moyenne 7 minutes. Quelle est la durée moyenne de son appel téléphonique si elle parle pendant plus de 3 minutes? Solution 3 \\(\\mathbb{E}(X)=\\sum x_i\\mathbb{P}(X=x_i)=100\\times 0.25+200\\times0.55+500\\times0.2=235.\\) \\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-\\mathbb{E}(X)^2=\\sum x_i^2\\mathbb{P}(X=x_i)-\\mathbb{E}(X)^2=74500-55225=19275.\\) \\(\\mathbb{E}(S_N)=\\mathbb{E}\\Big(\\mathbb{E}(S_N|N)\\Big)\\), avec \\(\\mathbb{E}(S_N|N)=\\mathbb{E}(X_1+X_2+\\ldots+X_N|N)\\). Or, \\(\\mathbb{E}(X_1+X_2+\\ldots+X_N|N)=\\mathbb{E}(X_1)+\\mathbb{E}(X_2)+\\ldots+\\mathbb{E}(X_N)=N\\mathbb{E}(X)\\) car \\(X_i\\) et \\(N\\) sont indépendantes. D’où \\(\\mathbb{E}\\Big(\\mathbb{E}(S_N|N)\\Big)=\\mathbb{E}(235 N)=235 \\mathbb{E}(N)=235 \\lambda\\). De même pour le calcul de la variance, \\(\\mathbb{V}\\Big(S_N\\Big)=\\mathbb{E}\\Big(\\mathbb{V}(S_N|N) \\Big)+\\mathbb{V}\\Big(\\mathbb{E}(S_N|N)\\Big)\\). \\(\\mathbb{V}(S_N|N)=\\mathbb{V}(X_1+X_2+\\ldots+X_N|N)=\\mathbb{V}(X_1)+\\mathbb{V}(X_2)+\\ldots+\\mathbb{V}(X_N)\\) car \\(X_i\\) sont indépendantes entre eux et avec \\(N\\). Donc \\(\\mathbb{V}(S_N|N)=N\\mathbb{V}(X)=19275 N\\). D’où, \\(\\mathbb{E}\\Big(\\mathbb{V}(S_N|N) \\Big)=\\mathbb{E}(19275 N)=19275 \\mathbb{E}(N)=19275 \\lambda\\). Et \\(\\mathbb{V}\\Big(\\mathbb{E}(S_N|N)\\Big)=\\mathbb{V}(235N)=235^2\\mathbb{V}(N)=55225 \\lambda\\). Ainsi, \\(\\mathbb{V}\\Big(S_N\\Big)=(19275+55225)\\lambda=74500 \\lambda\\). Reprenons les questions avec des simulations sous R # Créeons une fonction pour simuler la variable S_N # pour N=n sn.func &lt;- function(n){ sum(sample(c(100, 200, 500), n, replace=T, prob=c(0.25, 0.55, 0.2))) } # Générer 10,000 valeurs aléatoires de N, avec lambda=0.5: set.seed(12345) N &lt;- rpois(10000, lambda=0.5) # Générer 10,000 valeurs aléatoires de S_N, conditionallement à N: set.seed(12345) SN &lt;- sapply(N, sn.func) # Déterminons la moyenne de S_N, qui doit être proche de 235*0.5=117.5 mean(SN) [1] 116.74 # Déterminons la variance de S_N, qui doit être proche de 74500*0.5=37250 var(SN) [1] 36465.42 par(mfrow=c(1,2)) plot(cumsum(SN[-(1:10)])/(11:10000), type=&quot;l&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;Moyenne&quot;) abline(h=117.5, lwd=2, col=2) vvS=NULL for(i in 100:10000) vvS[i]=var(SN[1:i]) plot(vvS, type=&quot;l&quot;,xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;Variance&quot;) abline(h=37250, lwd=2,col=2) "],
["chaînes-de-markov.html", "Chapitre 2 Chaînes de Markov 2.1 Définitions et exemples 2.2 Loi des \\(X_n\\) 2.3 Classification des états 2.4 Temps d’absorption 2.5 Distribution limite 2.6 Simulation d’une chaîne de Markov discrète", " Chapitre 2 Chaînes de Markov La notion de ce qu’on appelle aujourd’hui une chaîne de Markov a été conçue par le mathématicien russe A.A. Markov. Une chaîne de Markov est un système mathématique qui subit des transitions d’un état à un autre selon un ensemble donné de règles probabilistes. Les chaînes de Markov sont des processus stochastiques, mais ils diffèrent en ce sens qu’ils doivent manquer de “mémoire”. Autrement dit, la probabilité de l’état suivant du système ne dépend que seulement de l’état actuel du système. Les chaînes de Markov sont largement utilisées dans de nombreux domaines tels que la finance, la théorie des jeux et la génétique. 2.1 Définitions et exemples Soit \\(X_0, X_1,\\ldots, X_n, \\ldots\\) une suite de variables aléatoires sur un espace de probabilité \\((\\Omega,\\mathcal{A}, \\mathbb{P})\\) à valeurs dans \\(E\\) (fini ou infini dénombrable). Définition 2.1 La suite \\((X_n)_{n \\in \\mathbb{N}}\\) est une chaîne de Markov si pour tout \\(n \\in \\mathbb{N}\\) et pour tout \\((x_0,x_1, \\ldots,x_{n+1}) \\in E^{n+2}\\) tel que \\(\\mathbb{P}(X_n=x_n, X_{n-1}=x_{n-1},\\ldots, X_0=x_0) &gt;0\\), \\(\\mathbb{P}(X_{n+1}=x_{n+1}|X_n=x_n,X_{n-1}=x_{n-1},\\ldots, X_0=x_0)\\) ne dépend que des valeurs \\(n\\), \\(x_n\\) et \\(x_{n+1}\\). L’ensemble \\(E\\) est appelé l’\\(\\color{blue}{\\mathbf{\\text{espace des états}}}\\) de la chîne de Markov et les \\(x_i\\) sont appelés \\(\\color{blue}{\\mathbf{\\text{états}}}\\). Proposition 2.1 Soit \\((X_n)_{n \\in \\mathbb{N}}\\) une chaine de Markov d’espace d’états \\(E\\). Pour tout \\(n \\in \\mathbb{N}\\) et pour tout \\((x_0,x_1x\\ldots,x_{n+1})\\in E^{n+2}\\), on a \\[\\mathbb{P}(X_{n+1}=x_{n+1}|X_n=x_n,X_{n-1}=x_{n-1},\\ldots, X_0=x_0)=\\mathbb{P}(X_{n+1}=x_{n+1}|X_n=x_n)\\] Définition 2.2 Une chaîne de Markov \\((X_n)_{n \\in \\mathbb{N}}\\) est dite homogène (dans le temps) si \\(\\mathbb{P}(X_{n+1}=x_{n+1}|X_n=x_n)\\) ne dépend pas de \\(n\\). La dynamique du processus est alors entièrement caractérisé par les \\(p_{ij}=\\mathbb{P}(X_{n+1}=j|X_n=i)\\), appelés \\(\\color{blue}{\\mathbf{\\text{probabilités de transitions}}}\\) de l’état \\(i\\) à l’état \\(j\\) si la chaîne est homogène, ou plus généralement \\[ p_{ij}^{(n)}=\\mathbb{P}(X_{n+1}=j|X_n=i)\\] Définition 2.3 Une matrice \\(P=(P_{ij},i,j \\in E)\\) est une matrice \\(\\color{blue}{\\mathbf{\\text{stochastique}}}\\), ou matrice \\(\\color{blue}{\\mathbf{\\text{de transition}}}\\) si chaque ligne \\(P_i=(P_{ij}, j \\in E)\\) est une distribution de probabilité. Pour tout \\(i,j \\in E\\), \\(p_{ij}\\) peut alors s’interpréter comme la probabilité d’aller à l’état \\(j\\) sachant qu’on se trouve à l’état \\(i\\) à l’instant précédent. Par exemple, la matrice suivante est une matrice stochastique \\[ P=\\left( \\begin{array}{cc} 0.2 &amp; 0.8\\\\ 0.4 &amp; 0.6 \\end{array} \\right) \\] (P&lt;-matrix(c(0.2,0.4,0.8,0.6),nc=2)) [,1] [,2] [1,] 0.2 0.8 [2,] 0.4 0.6 # vérifions que P est une matrice stochastique P&gt;=0 &amp; P&lt;=1 # 0&lt;= p &lt;=1 [,1] [,2] [1,] TRUE TRUE [2,] TRUE TRUE rowSums(P)==1 # somme pj = 1 [1] TRUE TRUE A toute matrice de transition, on peut associer un \\(\\color{blue}{\\mathbf{\\text{graphe orienté}}}\\). Les sommets sont les états de la chaîne, et l’orientation est donnée par la probabilité \\(p_{ij}&gt;0\\). Le graphe de la chaîne associé à la matrice de transition définie ci-dessus est donné par: # représenter un graphe sous R # install.packages(diagram) library(diagram) # charger l&#39;extension &#39;diagram&#39; P&lt;-matrix(c(0.2,0.4,0.8,0.6),nc=2) colnames(P) &lt;- c(&quot;S1&quot;, &quot;S2&quot;) rownames(P) &lt;- c(&quot;S1&quot;, &quot;S2&quot;) plotmat(t(P), pos=c(2),box.size = 0.05, box.prop = 0.7, box.col = &quot;gray&quot;, arr.pos = 0.6, relsize = 1.1) Exemple 2.1 Lors d’une ronde, une méthode simple pour tromper l’ennemi et d’avance ou reculer d’une manière aléatoire, en tirant pile ou face. On désigne par \\(X_n\\) la position de garde à l’instant \\(n\\). L’évolution peut se modéliser à l’aide d’une matrice de transition \\[ P=\\begin{array}{c c} &amp; \\begin{array}{c c c c} \\color{blue}{N} &amp; \\color{blue}{E} &amp; \\color{blue}{S} &amp; \\color{blue}{O} \\\\ \\end{array} \\\\ \\begin{array}{c c c c} \\color{blue}{N} \\\\ \\color{blue}{E}\\\\ \\color{blue}{S} \\\\ \\color{blue}{O} \\end{array} &amp; \\left( \\begin{array}{c c c c} 0 &amp; 0.5 &amp; 0 &amp; 0.5 \\\\ 0.5 &amp; 0 &amp; 0.5 &amp; 0 \\\\ 0 &amp; 0.5 &amp; 0 &amp; 0.5 \\\\ 0.5 &amp; 0 &amp; 0.5 &amp; 0 \\end{array} \\right) \\end{array}\\] L’ensemble des états, \\(E\\), est formé de 4 états {N, E, S, O}. La probabilité de se déplacer à l’état \\(E\\) sachant qu’on se trouve à l’état \\(N\\) est: \\[ \\mathbb{P}(X_{n+1}=E|X_n=N)=p_{12}=0.5 \\] Le graphe orienté correspondant à cette matrice de transition est: nn=c(&quot;N&quot;,&quot;E&quot;, &quot;S&quot;,&quot;O&quot;) P1=matrix(rep(c(0,0.5,0,0.5,0.5,0,0.5,0),2), nc=4, dimnames = list(nn,nn)) plotmat(t(P1), box.size = 0.05, box.prop = 0.6, box.col = &quot;gray&quot;, arr.pos = 0.7, relsize = 0.9) Exemple 2.2 La tendance d’un marché boursier peut être haussière (H), ou baissière (B) ou en consolidation (marché en range) (C). Le graphe associé est donné comme suit: On déduit la matrice de transition \\[ P=\\left( \\begin{array}{ccc} 0.85 &amp; 0.06 &amp; 0.09 \\\\ 0.05 &amp; 0.87 &amp; 0.08 \\\\ 0.5 &amp; 0.25 &amp; 0.25 \\end{array} \\right) \\] On note qu’un jour haussier est suivi par un autre jour haussier dans 85% des temps, par un jour baissier dans 6% des temps et par un jour de consolidation dans 9% des temps. Exercice 2.1 Dans un certain pays, il ne fait jamais beau deux jours de suite. Si un jour il fait beau, le lendemain il peut neiger ou pleuvoir avec autant de chances. Si un jour il pleut ou il neige, il y a une chance sur deux qu’il ait changement de temps le lendemain, et s’il y a changement, il y a une chance sur deux que ce soit pour du beau temps. Former une chaîne de Markov et en déterminer sa matrice de transition. Représenter le graphe orienté associé. Si on suppose l’on a que deux états (beau temps et mauvais temps), déterminer la matrice de la nouvelle chaîne ainsi obtenue. Solution 1.1 On a l’ensemble des états suivants \\(E=\\{B,P,N \\}\\). Le temps pour un jour ne dépend que seulement de temps du jour précédent. On a donc un processus de Markov. Il ne fait jamais beau deux jours de suite \\(\\Longrightarrow \\mathbb{P}(X_{n+1}=B|X_n=B)=0\\). Si un jour il fait beau, le lendemain il peut neiger ou pleuvoir avec autant de chances \\(\\Longrightarrow \\mathbb{P}(X_{n+1}=P|X_n=B)=\\mathbb{P}(X_{n+1}=N|X_n=B)=0.5\\). Si un jour il pleut ou il neige, il y a une chance sur deux qu’il ait changement de temps le lendemain \\(\\Longrightarrow P(X_{n+1}=P|X_n=P)=\\mathbb{P}(X_{n+1}=N|X_n=N)=0.5\\). et s’il y a changement, il y a une chance sur deux que ce soit pour du beau temps \\(\\mathbb{P}(X_{n+1}=B|X_n=P)=\\mathbb{P}(X_{n+1}=B|X_n=N)=0.5\\times 0.5=0.25\\). Ainsi, la matrice stochastique est donnée par: \\[ P=\\left( \\begin{array}{ccc} 0 &amp; 0.5 &amp; 0.5\\\\ 0.25 &amp; 0.5 &amp; 0.25\\\\ 0.25 &amp; 0.25 &amp; 0.5 \\end{array} \\right) \\] et le graphe orienté associé est: noms=c(&quot;B&quot;,&quot;P&quot;,&quot;N&quot;) PB=matrix(c(0,0.25,0.25,0.5,0.5,0.25,0.5,0.25,0.5), nc=3, dimnames = list(noms,noms)) plotmat(t(PB), box.size = 0.06, box.prop = 0.5, box.col = &quot;gray&quot;, arr.pos = 0.6, relsize = 0.85,dtext = 0.6) Le nouvel ensemble des états est \\(E_1=\\{B, M \\}\\), \\(M\\) pour désigner mauvais temps (soit il pleut, soit il neige). \\[\\mathbb{P}(X_{n+1}=B|X_n=M)=\\mathbb{P}(X_{n+1}=B|X_n=P)+\\mathbb{P}(X_{n+1}=B|X_n=N)=0.5+0.5=1\\] \\(\\mathbb{P}(X_{n+1}=B|X_n=B)=0\\). \\[\\begin{align*} \\mathbb{P}(X_{n+1}=M|X_n=M)&amp;=\\mathbb{P}(X_{n+1}=P|X_n=P)+\\mathbb{P}(X_{n+1}=P|X_n=N)\\\\ &amp; = \\mathbb{P}(X_{n+1}=N|X_n=N)+\\mathbb{P}(X_{n+1}=N|X_n=N)\\\\ &amp;= \\dfrac{1}{2}+\\dfrac{1}{4}= \\dfrac{3}{4} \\end{align*}\\] \\[\\begin{align*} \\mathbb{P}(X_{n+1}=M|X_n=B)&amp;=\\mathbb{P}(X_{n+1}=P|X_n=B)=\\mathbb{P}(X_{n+1}=N|X_n=B)\\\\ &amp;= \\dfrac{1}{4} \\end{align*}\\] Ainsi, la matrice de transition d’espace d’états \\(\\{B,M\\}\\) est: \\[ P_1=\\left( \\begin{array}{cc} 0 &amp; 1\\\\ \\frac{1}{4} &amp; \\frac{3}{4} \\end{array} \\right) \\] 2.2 Loi des \\(X_n\\) Le comportement d’une chaîne de Markov \\(X\\) dépend entièrement de sa matrice de transition \\(P\\), et de la position initiale \\(X_0\\). On appelle \\(\\mu_0\\) la \\(\\color{blue}{\\mathbf{\\text{loi initiale}}}\\) de \\(X\\), c’est une mesure définie par \\[ \\mu_0(x)=\\mathbb{P}(X_0=x) \\] Connaissant \\(\\mu_0\\) et \\(P\\), on peut calculer directement la loi de \\(X_n\\). La distribution de \\(X_1\\) est: \\[\\begin{align*} \\mathbb{P}(X_1 = j) = \\sum_{i=1}^N \\mathbb{P}(X_1 = j | X_0 = i)\\mathbb{P}(X_0 = i) \\\\ = \\sum_{i=1}^N \\mu_0(i) p_{ij}=(\\mu_0 P)_j\\; \\text{ pour tout }j \\end{align*}\\] La distribution de \\(X_2\\) est: \\[\\begin{align*} \\mathbb{P}(X_2 = j) = \\sum_{i=1}^N \\mathbb{P}(X_1 = j | X_0 = i)\\mathbb{P}(X_0 = i) \\\\ = \\sum_{i=1}^N \\mu_0(i) (P^2)_{ij}=(\\mu_0 P^2)_j\\; \\text{ pour tout }j \\end{align*}\\] Théoreme 2.1 Soit \\(\\{X_0, X_1, X_2, \\ldots \\}\\) une CM et \\(P\\) sa matrice de transition carré d’ordre \\(N\\). Si la distribution initiale, \\(\\mu_0\\) est donnée, alors la distribution de probabilité de \\(X_n\\) est donnée par \\(\\mu_0 P^n\\). \\[ X_0 \\sim \\mu_0 \\Longrightarrow X_n \\sim \\mu_0 P \\] Probabilité d’une trajectoire Rappelons qu’une trajectoire est une séquence de valeurs pour \\(X_0, X_1,\\ldots, X_n\\). La propriété de Markov nous permet de trouver la probabilité de n’importe quelle trajectoire en multipliant la probabilité de départ et toutes les probabilités à un pas ultérieures. Proposition 2.2 Pour toute suite \\(\\{x_0, x_1, \\ldots , x_n\\}\\) dans \\(E\\), on a \\(P(X_0 = x_0, X_1 = x_1,X_2 = x_2, \\ldots , X_n = x_n) =\\mu_0(x_0)P(x_0, x_1)P(x_1, x_2)\\ldots P(x_{n−1}, x_n)\\). Théoreme 2.2 (Equations de Chapman-Kolmogorov) Pour tout $(i, j) E^2 et tout couple \\((m, n)\\) d’entiers positifs, on a l’identité : \\[ \\mathbb{P}(X_{m+n} = j|X_0 = i) = \\sum_{k\\in E} \\mathbb{P}(X_m = k|X_0 = i)\\mathbb{P}(X_n = j|X_0 = k)\\] \\[\\text{ou encore } p^{(m+n)}_{ij} = \\sum_{k \\in E} p^{(m)}_{ik} p^{(n)}_{kj} \\text{ ou } (P^{m+n})_{ij}=(P^m)_{ik}(P^n)_{kj}\\] Exemple 2.3 Soit une CM définie par la matrice de transition \\[ P=\\left( \\begin{array}{cccc} 0.2 &amp; 0.4 &amp; 0.1 &amp; 0.3\\\\ 0 &amp; 0.5 &amp; 0.4 &amp; 0.1\\\\ 0.1 &amp; 0 &amp; 0.6 &amp; 0.3\\\\ 0.4 &amp; 0.15 &amp; 0.25 &amp; 0.2 \\end{array} \\right) \\] et de distribution initiale \\(\\mu_0 \\sim (0.3,0.2,0.5,0)\\). Déterminer \\(\\mathbb{P}(X_2=2)\\). Déterminer la probabilité des trajectoires: 1,2,3,4 et 2,3,1,1. \\(\\mathbb{P}(X_2=2)=\\left(\\mu_0 P^2 \\right)_{2}\\). \\[\\begin{align*} \\text{Or } \\mu_0 P^2=(0.3,0.2,0.5,0) \\left( \\begin{array}{cccc} 0.2 &amp; 0.4 &amp; 0.1 &amp; 0.3\\\\ 0 &amp; 0.5 &amp; 0.4 &amp; 0.1\\\\ 0.1 &amp; 0 &amp; 0.6 &amp; 0.3\\\\ 0.4 &amp; 0.15 &amp; 0.25 &amp; 0.2 \\end{array} \\right) \\left( \\begin{array}{cccc} 0.2 &amp; 0.4 &amp; 0.1 &amp; 0.3\\\\ 0 &amp; 0.5 &amp; 0.4 &amp; 0.1\\\\ 0.1 &amp; 0 &amp; 0.6 &amp; 0.3\\\\ 0.4 &amp; 0.15 &amp; 0.25 &amp; 0.2 \\end{array} \\right)\\\\ = (0.167,0.193,0.41,0.23)\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\; \\end{align*}\\] D’où \\(\\mathbb{P}(X_2=2)=0.193\\). Sous R, le produit matriciel s’effectue à l’aide de la fonction %*%. Pour la puissance d’ordre \\(n \\geq 2\\) d’une matrice carré, on peut utiliser la fonction %^% définie ci-dessous. P4=matrix(c(0.2,0,0.1,.4,.4,.5,0,.15,.1,.4,.6,.25, .3,.1,.3,.2), nc=4) mu0=c(.3,.2,.5,0) mu0%*%P4%*%P4 # %*% : produit matriciel [,1] [,2] [,3] [,4] [1,] 0.167 0.193 0.41 0.23 # puissance nième d&#39;une matrice carré power_matrix=function(A,n){ if(n==0) return(diag(rep(1,nrow(A)))) if(n==1) return(A) if(n&gt;1) return(A%*%power_matrix(A,(n-1))) } &quot;%^%&quot;&lt;-power_matrix P4%^%3 # P4^3 [,1] [,2] [,3] [,4] [1,] 0.1415 0.259 0.3835 0.216 [2,] 0.1385 0.193 0.4405 0.228 [3,] 0.1925 0.163 0.3885 0.256 [4,] 0.1670 0.244 0.3670 0.222 \\(\\mathbb{P}(1,2,3,4)=\\mathbb{P}(X_0=1)\\times P_{12}\\times P_{23}\\times P_{34}= 0.3 \\times 0.4 \\times 0.4 \\times 0.3 =\\) 0.0144. \\(\\mathbb{P}(2,3,1,1)=\\mathbb{P}(X_0=2)\\times P_{23}\\times P_{31}\\times P_{11}= 0.2 \\times 0.4 \\times 0.1 \\times 0.2 =\\) 0.0016. Pour le calcul de la probabilité d’une trajectoire donnée sous R, on peut utiliser la fonction suivante: ProbTraj&lt;-function(traj,mu0,X0, P){ n&lt;-length(traj)-1 pi&lt;-NULL for(k in 1:n) pi[k]&lt;-P[traj[k],traj[k+1]] mu0[X0]*prod(pi) } ProbTraj(c(1,2,3,4),mu0,X0=1,P4) [1] 0.0144 ProbTraj(c(2,3,1,1),mu0,X0=2,P4) [1] 0.0016 Exercice 2.2 On considère une CM à trois états dont la matrice de transition est la suivante : \\[ P=\\left( \\begin{array}{ccc} 0.6 &amp; 0.2 &amp; 0.2 \\\\ 0.4 &amp; 0 &amp; 0.6 \\\\ 0 &amp; 0.8 &amp; 0.2 \\end{array} \\right)\\] Calculer \\(\\mathbb{P}(X_2=3|X_0=1)\\). Solution 1.2 \\(\\mathbb{P}(X_2=3|X_0=1)\\) est la probabilité de se déplacer de l’état 1 à l’état 2 en deux étapes. Donc les trajectoires possibles sont: (1,2,3); (1,1,3) ou (1,3,3) avec \\(\\mu_0=(1,0,0)\\). \\[\\begin{align*} \\mathbb{P}(X_2=3|X_0=1)= \\left( P^2\\right)_{13} =\\left( \\begin{array}{ccc} 0.6 &amp; 0.2 &amp; 0.2 \\\\ . &amp; . &amp; . \\\\ . &amp; . &amp; . \\end{array} \\right)\\left( \\begin{array}{ccc} . &amp; . &amp; 0.2 \\\\ . &amp; . &amp; 0.4 \\\\ . &amp; . &amp; 0.2 \\end{array} \\right)\\\\ = 0.6 \\times 0.2 + 0.2 \\times 0.6 +0.2 \\times 0.2 = 0.28. \\end{align*}\\] P=matrix(c(0.6,0.4,0,0.2,0,0.8,0.2,0.6,0.2),nc=3) P[1,]%*%P[,3] [,1] [1,] 0.28 # ou encore # (1,2,3); (1,1,3); (1,3,3) ProbTraj(c(1,2,3),c(1,0,0),X0=1,P)+ProbTraj(c(1,1,3),c(1,0,0),X0=1,P)+ ProbTraj(c(1,3,3),c(1,0,0),X0=1,P) [1] 0.28 Exercice 2.3 On considère une chaîne de Markov à deux états dont la matrice de transition est la suivante : \\[ P=\\left( \\begin{array}{cc} 0.4 &amp; 0.6 \\\\ 0.6 &amp; 0.4 \\end{array} \\right)\\] Calculer la probabilité de l’événement \\(A_3\\) de passer pour \\(n \\leq 5\\) trois fois par l’état 2 si la loi initiale est \\(\\mu_0=(0.3,0.7)\\). Solution 1.3 \\(A_3=\\{n \\leq 5\\), on passe 3 fois par l’état 2 \\(\\}\\). Tout d’abord, déterminons les différentes possibilités. Si l’état initial est l’état \\(\\color{blue}{1}\\), on aura les possibilités suivantes: \\(x_1^1=(1, 1, 2, 2, 2)\\), \\(x_1^2=(1, 2,1, 2, 2)\\), \\(x_1^3=(1 ,2 ,2 ,1 , 2)\\) et \\(x_1^4=(1 , 2, 2, 2, 1)\\) D’où \\(\\mathbb{P}_1(A_3)=\\mathbb{P}(X=x_1^1)+\\mathbb{P}(X=x_1^2)+\\mathbb{P}(X=x_1^3)+\\mathbb{P}(X=x_1^4)\\) Avec \\(\\mathbb{P}(X=x_1^1)=\\mathbb{P}(X_0=1)\\times p_{11}\\times p_{12}\\times p_{22}\\times p_{22}=0.3 \\times 0.4 \\times 0.6 \\times 0.4 \\times 0.4=\\) 0.01152; \\(\\mathbb{P}(X=x_1^2)=\\mathbb{P}(X_0=1) \\times p_{12}\\times p_{21}\\times p_{12}\\times p_{22}=0.3\\times 0.6^3 \\times 0.4 =\\) 0.02592; \\(\\mathbb{P}(X=x_1^3)=\\mathbb{P}(X_0=1)\\times p_{12}\\times p_{22}\\times p_{21}\\times p_{12}=0.3\\times 0.6 \\times 0.4 \\times 0.6^2 =\\) 0.02592; \\(\\mathbb{P}(X=x_1^4)=\\mathbb{P}(X_0=1)\\times p_{12}\\times p_{22}\\times p_{22}\\times p_{21}=0.3\\times 0.6^2 \\times 0.4^2 =\\) 0.01728; Donc \\(\\mathbb{P}_1(A_3)= 0.01152+0.02592+0.02592+0.01728=\\) 0.08064. Si l’état initial est l’état \\(\\color{blue}{2}\\), on aura: \\(x_2^1=(2,1, 1, 2, 2)\\), \\(x_2^2=(2, 1, 2, 1,2)\\), \\(x_2^3=(2 , 1 , 2, 2, 1)\\), \\(x_2^4=(2, 2, 1, 2, 1)\\), \\(x_2^5=(2, 2 , 1 , 1 , 2)\\) et \\(x_2^6=(2, 2, 2 , 1 , 1)\\). D’où \\(\\mathbb{P}_2(A_3)=P(X=x_2^1)+P(X=x_2^2)+P(X=x_2^3)+P(X=x_2^4)+P(X=x_2^5)+P(X=x_2^6)\\). \\(\\mathbb{P}_2(A_3)=0.3192\\). Ainsi \\(\\mathbb{P}(A_3)=\\mu_0(1)\\times \\mathbb{P}_1(A_3)+\\mu_0(2)\\times \\mathbb{P}_2(A_3)=\\) 0.247632. tab1=matrix(c(1,1,2,2,2,1,2,1,2,2,1,2,2,1,2,1,2,2,2,1),nr=5) mu0=c(0.3,0.7) P2=matrix(c(0.4,0.6,0.6,0.4),nc=2) (probs1=apply(tab1,2,ProbTraj,mu0,1,P2)) [1] 0.01152 0.02592 0.02592 0.01728 sum(probs1) # P1(A3) [1] 0.08064 tab2=matrix(c(2,1,1,2,2,2,1,2,1,2,2,1,2,2,1,2,2,1,2,1,2,2,1,1,2,2,2,2,1,1),nr=5) (probs2=apply(tab2,2,ProbTraj,mu0,2,P2)) [1] 0.04032 0.09072 0.06048 0.06048 0.04032 0.02688 sum(probs2) # P2(A3) [1] 0.3192 PA3=mu0%*%c(sum(probs1),sum(probs2)) ; as.vector(PA3) #P(A3) [1] 0.247632 2.3 Classification des états L’espace des états d’une CM peut être partitionné en un ensemble de classes communicantes disjointes. Définition 2.4 On dit que l’état \\(j\\) est \\(\\color{blue}{\\mathbf{\\text{accessible}}}\\) à partir de l’état \\(i\\), s’il existe un entier \\(n \\geq 0\\) tel que \\(P^{(n)}_{ij} &gt;0\\). On note \\(i \\longrightarrow j\\). Sur le graphe, si \\(i \\neq j\\), \\(i\\longrightarrow j\\) s’il existe un chemin (orienté) du sommet \\(i\\) vers le sommet \\(j\\). Si \\(j\\) est accessible à partir de \\(i\\) et \\(i\\) est accessible depuis \\(j\\), on dit que \\(i\\) et \\(j\\) \\(\\color{blue}{\\mathbf{\\text{communiquent}}}\\) et on note \\(i \\longleftrightarrow j\\). On note que si \\(i \\longrightarrow k\\) et \\(k \\longrightarrow j\\), alors \\(i \\longrightarrow j\\) (la relation d’accessibilité est transitive). Définition 2.5 Les états \\(i\\) et \\(j\\) sont dans la même classe communicante si \\(i \\longleftrightarrow j\\). Exemple 2.4 Trouvez les classes communicantes associées au diagramme de transition suivant. D’après le diagramme, on remarque que \\(1 \\longleftrightarrow 2\\), \\(2 \\longleftrightarrow 3\\) et \\(4 \\longleftrightarrow 5\\). Donc on a deux classes communicantes \\(\\{1,2,3\\}\\) et \\(\\{4,5 \\}\\). Définition 2.6 Une classe d’états communicante est fermée s’il est impossible de quitter cette classe. Autrement dit, la classe \\(C\\) communicante est fermée si \\(p_{ij} = 0\\) pour tout \\(i \\in C\\) et \\(j \\notin C\\). Dans l’exemple précédent: La classe \\(\\{1,2,3\\}\\) n’est pas fermée car on peut la quitter (\\(2 \\longrightarrow 4\\)). La classe \\(\\{4,5\\}\\) est fermée car on ne peut pas la quitter. Définition 2.7 Si la chaîne de Markov ne possède qu’une unique classe, c’est à dire que tous ses éléments communiquent, la chaîne sera dite \\(\\color{blue}{\\mathbf{\\text{irréductible}}}\\). Un état \\(i\\) est dite \\(\\color{blue}{\\mathbf{\\text{absorbant}}}\\) si \\(\\{i\\}\\) est une classe fermée. Exemple 2.5 On considère la CMD à tois états 1, 2, 3 et de matrice stochastique \\[ P=\\left( \\begin{array}{ccc} 1/2 &amp; 1/2 &amp; 0 \\\\ 1/2 &amp; 1/4 &amp; 1/4 \\\\ 0 &amp; 1/3 &amp; 2/3\\\\ \\end{array} \\right) \\] Comme \\(1 \\longleftrightarrow 2\\) et \\(2 \\longleftrightarrow 3\\), alors cette CM est irréductible. Pour étudier la classification d’une CMD sous R, on peut procéder comme suit: # install.packeges(&quot;markovchain&quot;) # Installation de l&#39;extension markovchain library(markovchain) pp=matrix(c(0.5,0.5,0,0.5,0.25,1/3,0,0.25,2/3), nc=3, dimnames = list(c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;),c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;))) cm1=new(&quot;markovchain&quot;, transitionMatrix=pp) is.irreducible(cm1) # tester si la CM est irreductible [1] TRUE Exemple 2.6 Soit la CMD à quatre états définie par la matrice stochastique \\[ P=\\left( \\begin{array}{cccc} 1/2 &amp; 1/2 &amp; 0 &amp;0\\\\ 1/2 &amp; 1/2 &amp; 0 &amp; 0 \\\\ 0&amp; 0 &amp; 1/4 &amp; 3/4\\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{array} \\right) \\] Cette CM possède trois classes: \\(\\{1,2\\}\\), \\(\\{3\\}\\) et \\(\\{4\\}\\), donc elle est non irréductible. L’états 4 est absorbant car \\(\\{4\\}\\) est une classe fermée. p15=matrix(c(0.5,0.5,0,0,0.5,0.5,0,0,0,0,0.25,0,0,0,0.75,1), nc=4, dimnames = list(c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;),c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;))) cm2=new(&quot;markovchain&quot;, transitionMatrix= p15) is.irreducible(cm2) # tester si la CM est irréductible [1] FALSE absorbingStates(cm2) # déterminer les états absorbants [1] &quot;4&quot; 2.4 Temps d’absorption Dans cette section on se pose la question suivante : Etant donné une chaîne \\(X\\) et \\(x\\) dans l’espace d’états \\(E\\), quel est le temps moyen (éventuellement infini) que met \\(X\\) à arriver au temps \\(x\\). 2.4.1 Temps d’arrêt Pour \\(x \\in E\\) on définit le temps aléatoire \\[ T_x = \\min\\{n \\geq 0 : X_n = x\\}, \\] premier moment où la chaîne atteint l’état \\(x\\). Définition 2.8 Soit \\(A\\) un sous ensemble de l’espace d’états \\(E\\). Le temps d’atteinte de \\(A\\) est la variable aléatoire \\(T_A\\) définie par: \\[ T_A = \\min\\{n \\geq 0 : X_n \\in A \\}, \\] Notons que la probabilité d’atteindre \\(A\\) dépuis \\(i\\) est \\(h_{A|i} = P(T_A &lt; \\infty |X_0 = i)\\). \\(T_A\\) est le temps nécessaire pour atteindre l’ensemble \\(A\\) pour la première fois. \\(T_A\\) peut prendre les valeurs \\(0,1,2,\\ldots , \\infty\\). Si la chaîne ne peut jamais atteindre \\(A\\), alors \\(T_A= \\infty\\). Le temps d’atteinte est appelé aussi temps d’arrêt. Si \\(A\\) est une classe fermée, \\(T_A\\) sera appelé le temps d’absorption et \\(h_{A|i}\\) la probabilité d’absorption. Définition 2.9 Le temps moyen d’atteinte de \\(A\\), à partir de \\(i\\) est: \\[ m_{iA}=\\mathbb{E}\\left(T_A | X_0=i \\right)\\] Théoreme 2.3 Le vecteur des probabilités d’atteindre \\(A\\), \\(\\mathbf{h}_A=(h_{iA}, i \\in E)\\) est la solution minimale non négative du système suivant: \\[ h_{iA}=\\left\\{ \\begin{array}{ll} 1 &amp; \\text{ si } i \\in A\\\\ \\displaystyle \\sum_{j \\in E}p_{ij}h_{jA} &amp; \\text{ si } i \\notin A \\end{array} \\right. \\] Matriciellement, le vecteur \\(\\mathbf{h}_A\\) est solution du programme suivant: \\[ \\mathbf{h}_A = P_A \\mathbf{h}_A \\] où \\(P_A\\) est obtenue à partir de \\(P\\) en éliminant la (ou les) ligne(s) \\(i \\in A\\). Théoreme 2.4 Le vecteur des temps moyens d’atteinte de \\(A\\), à partir de \\(i\\), \\(\\mathbf{m}_A=(m_{iA}, i \\in E)\\) est la solution minimale non négative du système suivant: \\[ m_{iA}=\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si } i \\in A\\\\ 1+\\displaystyle \\sum_{j \\notin A}p_{ij}m_{jA} &amp; \\text{ si } i \\notin A \\end{array} \\right. \\] Exemple 2.7 On considère la chaîne suivante Déterminer le vecteur des probabilités d’ateinte de l’état 4. Déterminer le temps moyen d’atteinte de \\(A=\\{1,4\\}\\), à partir de \\(2\\). 1) Le vecteur des probabilités d’atteindre \\(4\\), à partir de \\(i=\\{1,2,3,4\\}\\) est la solution minimale de \\(P_4\\mathbf{h}_4=\\mathbf{h}_4\\). avec \\(h_{44}=1\\) et \\(P_4=\\left(\\begin{array}{cccc} 1 &amp; 0 &amp; 0 &amp; 0\\\\ \\frac{1}{2} &amp; 0 &amp; \\frac{1}{2} &amp; 0 \\\\ 0 &amp; \\frac{1}{2} &amp; 0 &amp; \\frac{1}{2} \\end{array}\\right)\\). Donc, on aura le système suivant: \\(\\left\\{\\begin{array}{l} h_{14}= h_{14} \\\\ h_{24}=\\frac{1}{2} h_{14}+\\frac{1}{2} h_{34}\\\\ h_{34}=\\frac{1}{2} h_{24}+\\frac{1}{2} h_{44}\\\\ h_{44}=1 \\quad (\\text{ car } 4 \\in A) \\end{array} \\right.\\) Comme \\(h_{14}\\) est une valeur quelconque, donc la valeur minimale non négative est \\(h_{14}=0\\). D’où, la solution du système est: \\[\\mathbf{h}_4=\\left(0,\\frac{1}{3}, \\frac{2}{3}, 1 \\right) \\] Sous R, on peut trouver le vecteur d’atteindre un état \\(i\\) à l’aide de la fonction hittingProbabilities() du package markovchain. etats=as.character(1:4) matP=matrix(c(1,0,0,0,.5,0,.5,0,0,.5,0,.5,0,0,0,1), nc=4, byrow = T, dimnames = list(etats,etats)) cm2=new(&quot;markovchain&quot;, transitionMatrix=matP) h4=hittingProbabilities(cm2)[,4] MASS::fractions(h4) 1 2 3 4 0 1/3 2/3 1 2) A partir de l’état \\(i = 2\\), on souhaite trouver le temps espéré pour atteindre l’ensemble \\(A = \\{1, 4\\}\\) (l’ensemble des états absorbants). \\[ m_{iA}=\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si } i \\in \\{1,4\\}\\\\ 1+\\displaystyle \\sum_{j \\notin A}p_{ij}m_{jA} &amp; \\text{ si } i \\notin \\{1,4\\} \\end{array} \\right. \\] Donc, \\(m_{1A}=m_{4A}=0\\) et \\[ \\left\\{ \\begin{array}{l}m_{2A}= 1+\\dfrac{1}{2}m_{1A}+\\dfrac{1}{2}m_{3A}=1+\\dfrac{1}{2}m_{3A} \\\\ m_{3A}= 1+\\dfrac{1}{2}m_{2A}+\\dfrac{1}{2}m_{4A}=1+\\dfrac{1}{2}m_{2A} \\end{array} \\right. \\Longleftrightarrow m_{2A}=m_{3A}=2. \\] Sous R, on peut retrouver le ésultat à l’aide de la fonction meanAbsoptionTime() du package markovchain. meanAbsorptionTime(cm2) 2 3 2 2 2.5 Distribution limite Définition 2.10 Une distribution de probabilité \\(\\pi\\) satisfaisant l’équation de balance globale \\(\\pi =\\pi P\\) est appelée distribution stationnaire de la matrice de transition \\(P\\), ou de la chaîne de Markov avec \\(\\pi_j \\geq 0\\) et \\(\\sum \\pi_j=1\\). La distribution \\(\\pi\\) est appelée aussi distribution invariante ou aussi distribution d’équilibre. Exemple 2.8 Soit \\(P=\\left(\\begin{array}{ccc} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; \\frac{1}{2} &amp; \\frac{1}{2}\\\\ \\frac{1}{2} &amp; 0 &amp; \\frac{1}{2} \\end{array}\\right)\\) Déterminer la distribution stationnaire de \\(P\\). La distribution stationnaire de \\(P\\) est solution du système \\[\\left\\{\\begin{array}{l} \\pi P =\\pi\\\\ \\pi \\mathbf{1}=1 \\end{array} \\right. \\; \\Longleftrightarrow \\left\\{\\begin{array}{l} \\pi_1 =\\frac{1}{2}\\pi_3\\\\ \\pi_2 =\\pi_1+\\frac{1}{2}\\pi_2\\\\ \\pi_3 =\\frac{1}{2}\\pi_2+\\frac{1}{2}\\pi_3\\\\ \\pi_1+\\pi_2+\\pi_3=1 \\end{array} \\right.\\; \\Longleftrightarrow \\pi=\\left(\\frac{1}{5},\\frac{2}{5},\\frac{2}{5}\\right) \\] Sous R, on peut déterminer le vecteur de probabilité stationnaire en résolvant un système linéaire d’équations \\[ \\left\\{\\begin{array}{l} \\pi_1 =\\frac{1}{2}\\pi_3\\\\ \\pi_2 =\\pi_1+\\frac{1}{2}\\pi_2\\\\ \\pi_3 =\\frac{1}{2}\\pi_2+\\frac{1}{2}\\pi_3\\\\ \\pi_1+\\pi_2+\\pi_3=1 \\end{array} \\right. \\Longleftrightarrow \\left\\{\\begin{array}{l} \\pi_1 -\\frac{1}{2}\\pi_3=0\\\\ \\pi_1-\\frac{1}{2}\\pi_2=0\\\\ \\pi_3 -\\pi_2=0\\\\ \\pi_1+\\pi_2+\\pi_3=1 \\end{array} \\right. \\Longleftrightarrow \\left( \\begin{array}{ccc} 1 &amp; 0 &amp;-\\frac{1}{2}\\\\ 1 &amp; -\\frac{1}{2} &amp; 0\\\\ 0&amp; -1 &amp; 1\\\\ 1 &amp; 1 &amp; 1 \\end{array}\\right)\\left( \\begin{array}{c} \\pi_1\\\\ \\pi_2\\\\ \\pi_3 \\end{array}\\right) = \\left( \\begin{array}{c} 0\\\\ 0\\\\ 0\\\\ 1 \\end{array}\\right)\\] P=matrix(c(0,0,1/2,1,1/2,0,0,1/2,1/2),3) A=matrix(c(1,1,0,1,0,-0.5,-1,1,-0.5,0,1,1),nc=3) b=c(0,0,0,1) MASS::fractions(t(solve(crossprod(A),crossprod(A,b)))) [,1] [,2] [,3] [1,] 1/5 2/5 2/5 2.5.1 Détermination de la distribution stationnaire On note que \\(\\pi P=\\pi\\) est très similaire à \\(AV=\\lambda V\\) avec \\(\\lambda=1\\). Donc \\(V\\) est le vecteur propre de \\(A\\) correspondant à la valeur propre \\(\\lambda=1\\). En effet, \\(\\left(\\pi P\\right)&#39;=\\pi&#39; \\Longleftrightarrow P&#39;\\pi&#39;=\\pi&#39;\\). En d’autres termes, la transposée de la matrice stochastique \\(P\\) possède une valeur propre \\(\\lambda=1\\) et le vecteur propre correspondant à cette valeur est la distribution stationnaire de \\(P\\). Reprenons l’exemple précédent. Tout d’abord, vérifions que \\(\\lambda=1\\) est une valeur propre de \\(P&#39;\\). \\(\\left|P&#39;-I\\right|=0 \\Longleftrightarrow \\left| \\begin{array}{ccc} -1 &amp; 0 &amp; \\frac{1}{2}\\\\ 1 &amp; -\\frac{1}{2} &amp; 0\\\\ 0 &amp; \\frac{1}{2} &amp; -\\frac{1}{2} \\end{array} \\right|=0\\) Déterminons le vecteur propre associé à \\(\\lambda=1\\). \\(P&#39;V=V \\Longleftrightarrow \\left\\{ \\begin{array}{l} \\frac{1}{2}z=x\\\\ x+\\frac{1}{2}y=y\\\\ \\frac{1}{2}y + \\frac{1}{2}z =z \\end{array} \\right. \\Longleftrightarrow \\left\\{ \\begin{array}{l} x=\\frac{1}{2}z\\\\ y=z\\\\ z \\in \\mathbb{R} \\end{array} \\right.\\) \\(V&#39;=(x,y,z)=z(\\frac{1}{2},1,1)\\), donc \\(V&#39;=(\\frac{1}{2},1,1)\\) est un vecteur propre de \\(P&#39;\\) associé à la valeur propre \\(\\lambda=1\\). Ainsi \\(\\pi=\\dfrac{V&#39;}{\\frac{1}{2}+1+1}=\\dfrac{2}{5}V&#39;=\\left(\\dfrac{1}{5},\\dfrac{2}{5},\\dfrac{2}{5}\\right)\\). # vecteur propre correspondant à 1 V=eigen(t(P))$vectors[,1]; V=Re(V) pi=V/sum(V); MASS::fractions(pi) [1] 1/5 2/5 2/5 2.5.2 Comportement de long terme Reprenons l’exemple précédent et déterminons \\(P^{20}\\), \\(P^{100}\\) et \\(\\displaystyle{\\lim_{n \\rightarrow \\infty}}P^n\\). P%^%20 [,1] [,2] [,3] [1,] 0.2000008 0.3999996 0.3999996 [2,] 0.1999998 0.4000006 0.3999996 [3,] 0.1999998 0.3999996 0.4000006 P%^%100 [,1] [,2] [,3] [1,] 0.2 0.4 0.4 [2,] 0.2 0.4 0.4 [3,] 0.2 0.4 0.4 2.6 Simulation d’une chaîne de Markov discrète 2.6.1 Exemple illustratif L’idée générale pour simuler une chaînes de Markov discrète peut être illustrée par un exemple simple à 2 états. Supposons que notre espace d’états est {1,2} et que la matrice de transition est: \\[ P=\\left( \\begin{array}{cc} 0.2 &amp; 0.8 \\\\ 0.4 &amp; 0.6 \\end{array} \\right)\\] Supposons maintenant que notre chaîne de Markov commence à l’état 1 de sorte que \\(X_0 = 1\\). Puisque nous commençons à l’état 1, nos probabilités de transition sont définies par la première ligne de \\(P\\). Notre chaîne peut soit rester à l’état 1 avec une probabilité \\(P_{11}=0.2\\), soit passer à l’état 2 avec une probabilité \\(P_{12}=0.8\\). Par conséquent, pour simuler \\(X_1\\), il faut générer une variable aléatoire selon les probabilités \\(P_{11} = P (X_1 = 1 | X_0 = 1) = 0.2\\) et \\(P_{12} = P (X_1 = 2 | X_0 = 0) = 0.8\\). En général, nous pouvons générer n’importe quelle variable aléatoire discrète selon un ensemble de probabilités \\(p = \\{p_1,\\ldots, p_K\\}\\) avec la méthode de transformation inverse. Notez également que cela équivaut à prendre un seul tirage à partir d’une distribution multinomiale avec un vecteur de probabilité \\(p\\) - nous utilisons cette méthode dans l’algorithme ci-dessous. Algorithme Obtenir la matrice de transition de probabilité \\(S\\times S\\), \\(P\\). Définir \\(t=0\\). Choisissez un état initial \\(X_0 = x_0\\). pour \\(t=1, \\ldots , T\\): Obtenir la ligne de \\(P\\) correspondante à l’état actuel \\(X_t\\) Génère \\(X_{t + 1}\\) à partir d’une distribution multinomiale avec un vecteur de probabilité égal à la ligne que nous avons obtenue ci-dessus. Nous implémentons cet algorithm dans la fonction suivante: # simuler des CMD selon la matrice de transition P sim_CMD &lt;- function( P, N = 50, x0=1 ) { # nombre des états n_etats &lt;- nrow(P) etats &lt;- numeric(N) # valeur de l&#39;état initial etats[1] &lt;- x0 for(t in 2:N) { # vecteur de prob pour simuller l&#39;état suivant X_{t+1} p &lt;- P[etats[t-1], ] ## tirer depuis la distribution multinomiale et déterminer l&#39;état etats[t] &lt;- which(rmultinom(1, 1, p) == 1) } return(etats) } 2.6.1.1 Simulation de l’exemple illustratif (P &lt;- matrix(c(0.2,0.4,0.8,0.6), nc=2)) [,1] [,2] [1,] 0.2 0.8 [2,] 0.4 0.6 sim1&lt;-sim_CMD(P,N=100, x0=1) head(sim1) [1] 1 2 2 2 2 2 sim11&lt;-replicate(sim_CMD(P,N=50, x0=1),n=100) mean(sim11[2,sim11[1,]==1]==1) # p11=p(X_1=1|X_0=1)=0.2 [1] 0.21 mean(sim11[1,sim11[1,]==1]==1) # p12=p(X_1=1|X_0=1)=0.2 [1] 1 "],
["processus-de-poisson.html", "Chapitre 3 Processus de poisson", " Chapitre 3 Processus de poisson "],
["processus-gaussien.html", "Chapitre 4 Processus Gaussien", " Chapitre 4 Processus Gaussien "],
["applications.html", "Chapitre 5 Applications 5.1 Example one 5.2 Example two", " Chapitre 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],
["bibliographie.html", "Bibliographie", " Bibliographie "]
]
