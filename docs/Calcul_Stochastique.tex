% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Calcul stochastique},
  pdfauthor={Mohamed Essaied Hamrita},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage[francais]{babel}
\usepackage{xcolor}
%\usepackage{kbordermatrix}
\usepackage[utf8]{inputenc}
\usepackage[top=2cm, right=2cm,left=2.5cm,bottom=2cm]{geometry}
%\newtheorem{sol}[exercise]{Solution}
\newcommand{\Nn}{\mathbb{N}}
\newcommand{\Rr}{\mathbb{R}}
\newcommand{\Pp}{\mathbb{P}}
%\usepackage{unicode-math}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\bf\thepage}
\lhead{\bf\sffamily\nouppercase{\rightmark}}
\rfoot{\bf FSEG Sousse}
\lfoot{\bf\sffamily Mohamed Essaied Hamrita}

\title{Calcul stochastique}
\author{Mohamed Essaied Hamrita}
\date{2021}

\usepackage{amsthm}
\newtheorem{theorem}{Théoreme}[chapter]
\newtheorem{lemma}{Lemme}[chapter]
\newtheorem{corollary}{Corollaire}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Définition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Exemple}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remarque }
\newtheorem*{solution}{Solution }
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{rappel-sur-le-calcul-des-probabilituxe9s}{%
\chapter{Rappel sur le calcul des probabilités}\label{rappel-sur-le-calcul-des-probabilituxe9s}}

\hypertarget{notion-de-probabilituxe9}{%
\section{Notion de probabilité}\label{notion-de-probabilituxe9}}

Une notion basique dans la théorie des probabilités est l'\textbf{expérience aléatoire} dont on ne connait pas son résultat en avance. L'ensemble de tous les résultats de l'expérience est l'\textbf{ensemble des possibles} ou encore l'\textbf{univers} et noté \(\Omega\).

Un \textbf{évènement} est un sous ensemble de l'univers.

On donne quelques exemples:

\textbf{1.} Si l'expérience consiste à jeter une pièce de monnaie, alors \(\Omega=\{P,F\}\).

\textbf{2.} Si l'expérience consiste à jeter un dé cubique dont ses faces sont numérotées de 1 à 6, alors \(\Omega=\{1,2,3,4,5,6 \}\).

Pour chaque évènement \(E\) de l'univers \(\Omega\), on définit un nombre \(P(E)\) qui satisfait les axiomes suivants:

\begin{itemize}
\tightlist
\item
  \textbf{Axiome 1:} \(0 \leq P(E) \leq 1\);
\item
  \textbf{Axiome 2:} \(P(\Omega)=1\);
\item
  \textbf{Axiome 3:} Pour toute séquence des évènements \(E_1 , E_2, \ldots , E_n\) qui sont mutuellement exclusifs (\(E_i \cap E_j=\emptyset , \; \forall \; i \neq j\) et \(\displaystyle{\bigcup\limits_{i=1}^nE_i=\Omega}\)), on a
  \[
  P \left(\bigcup\limits_{i=1}^nE_i \right)=\sum_{i=1}^n P(E_i)
  \]
\end{itemize}

Quelques conséquences de ces axiomes sont tirées:

\begin{itemize}
\tightlist
\item
  Si \(E \subset F\), alors \(P(E) \leq P(F)\).
\item
  \(P ( \bar{E})=1-P(E)\) où \(\bar{E}\) est le complémentaire de \(E\).
\item
  \(P \left(\bigcup\limits_{i=1}^nE_i \right)=\displaystyle\sum_{i=1}^n P(E_i)\), lorsque \(E_i\) sont mutuellement exclusifs.
\item
  \(P \left(\bigcup\limits_{i=1}^nE_i \right)\leq\displaystyle \sum_{i=1}^n P(E_i)\) (Inégalité de Boole).
\end{itemize}

\hypertarget{chauxeenes-de-markov}{%
\chapter{Chaînes de Markov}\label{chauxeenes-de-markov}}

La notion de ce qu'on appelle aujourd'hui une chaîne de Markov a été conçue par le mathématicien russe A.A. Markov.

Une chaîne de Markov est un système mathématique qui subit des transitions d'un état à un autre selon un ensemble donné de règles probabilistes. Les chaînes de Markov sont des processus stochastiques, mais ils diffèrent en ce sens qu'ils doivent manquer de ``mémoire''. Autrement dit, la probabilité de l'état suivant du système ne dépend que \textbf{seulement} de l'état actuel du système.

Les chaînes de Markov sont largement utilisées dans de nombreux domaines tels que la finance, la théorie des jeux et la génétique.

\hypertarget{duxe9finitions-et-exemples}{%
\section{Définitions et exemples}\label{duxe9finitions-et-exemples}}

Soit \(X_0, X_1,\ldots, X_n, \ldots\) une suite de variables aléatoires sur un espace de probabilité \((\Omega,\mathcal{A}, \mathbb{P})\) à valeurs dans \(E\) (fini ou infini dénombrable).

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-3}{}{\label{def:unnamed-chunk-3} }La suite \((X_n)_{n \in \mathbb{N}}\) est une chaîne de Markov si pour tout \(n \in \mathbb{N}\) et pour tout \((x_0,x_1, \ldots,x_{n+1}) \in E^{n+2}\) tel que \(P(X_n=x_n, X_{n-1}=x_{n-1},\ldots, X_0=x_0) >0\), \(P(X_{n+1}=x_{n+1}|X_n=x_n,X_{n-1}=x_{n-1},\ldots, X_0=x_0)\) ne dépend que des valeurs \(n\), \(x_n\) et \(x_{n+1}\).
\end{definition}
L'ensemble \(E\) est appelé l'\(\color{blue}{\mathbf{\text{espace des états}}}\) de la chîne de Markov et les \(x_i\) sont appelés \(\color{blue}{\mathbf{\text{états}}}\).
\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-4}{}{\label{prp:unnamed-chunk-4} }Soit \((X_n)_{n \in \mathbb{N}}\) une chaine de Markov d'espace d'états \(E\). Pour tout \(n \in \mathbb{N}\) et pour tout \((x_0,x_1x\ldots,x_{n+1})\in E^{n+2}\), on a
\[P(X_{n+1}=x_{n+1}|X_n=x_n,X_{n-1}=x_{n-1},\ldots, X_0=x_0)=P(X_{n+1}=x_{n+1}|X_n=x_n)\]
\end{proposition}

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-5}{}{\label{def:unnamed-chunk-5} }Une chaîne de Markov \((X_n)_{n \in \mathbb{N}}\) est dite homogène (dans le temps) si \(P(X_{n+1}=x_{n+1}|X_n=x_n)\) ne dépend pas de \(n\).
\end{definition}

La dynamique du processus est alors entièrement caractérisé par les \(p_{ij}=P(X_{n+1}=j|X_n=i)\), appelés \(\color{blue}{\mathbf{\text{probabilités de transitions}}}\) de l'état \(i\) à l'état \(j\) si la chaîne est homogène, ou plus généralement
\[ p_{ij}^{(n)}=P(X_{n+1}=j|X_n=i)\]
\begin{definition}
\protect\hypertarget{def:unnamed-chunk-6}{}{\label{def:unnamed-chunk-6} }Une matrice \(P=(P_{ij},i,j \in E)\) est une matrice \(\color{blue}{\mathbf{\text{stochastique}}}\), ou matrice \(\color{blue}{\mathbf{\text{de transition}}}\) si chaque ligne \(P_i=(P_{ij}, j \in E)\) est une distribution de probabilité.
\end{definition}

Pour tout \(i,j \in E\), \(p_{ij}\) peut alors s'interpréter comme la probabilité d'aller à l'état \(j\) sachant qu'on se trouve à l'état \(i\) à l'instant précédent.

Par exemple, la matrice suivante est une matrice stochastique

\[
P=\left( 
\begin{array}{cc}
0.2 & 0.8\\
0.4 & 0.6
\end{array}
\right)
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(P<-}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.6}\NormalTok{),}\DataTypeTok{nc=}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,]  0.2  0.8
[2,]  0.4  0.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# vérifions que P est une matrice stochastique}
\NormalTok{P}\OperatorTok{>=}\DecValTok{0} \OperatorTok{&}\StringTok{ }\NormalTok{P}\OperatorTok{<=}\DecValTok{1}  \CommentTok{# 0<= p <=1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,] TRUE TRUE
[2,] TRUE TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rowSums}\NormalTok{(P)}\OperatorTok{==}\DecValTok{1} \CommentTok{# somme pj = 1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE TRUE
\end{verbatim}

A toute matrice de transition, on peut associer un \(\color{blue}{\mathbf{\text{graphe orienté}}}\). Les sommets sont les états de la chaîne, et l'orientation est donnée par la probabilité \(p_{ij}>0\).

Le graphe de la chaîne associé à la matrice de transition définie ci-dessus est donné par:

\begin{center}\includegraphics[width=8.36in]{images/graph1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# représenter un graphe sous R}
\CommentTok{# install.packages(diagram)}
\KeywordTok{library}\NormalTok{(diagram) }\CommentTok{# charger l'extension 'diagram'}
\NormalTok{P<-}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.6}\NormalTok{),}\DataTypeTok{nc=}\DecValTok{2}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(P) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"S1"}\NormalTok{, }\StringTok{"S2"}\NormalTok{)}
\KeywordTok{rownames}\NormalTok{(P) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"S1"}\NormalTok{, }\StringTok{"S2"}\NormalTok{)}
\KeywordTok{plotmat}\NormalTok{(}\KeywordTok{t}\NormalTok{(P), }\DataTypeTok{pos=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{),}\DataTypeTok{box.size =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{box.prop =} \FloatTok{0.7}\NormalTok{, }
      \DataTypeTok{box.col =} \StringTok{"gray"}\NormalTok{, }\DataTypeTok{arr.pos =} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{relsize =} \FloatTok{1.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Calcul_Stochastique_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-10}{}{\label{exm:unnamed-chunk-10} }Lors d'une ronde, une méthode simple pour tromper l'ennemi et d'avance ou reculer d'une manière aléatoire, en tirant pile ou face. On désigne par \(X_n\) la position de garde à l'instant \(n\). L'évolution peut se modéliser à l'aide d'une matrice de transition
\[
 P=\begin{array}{c c} &
\begin{array}{c c c c} \color{blue}{N} & \color{blue}{E} & \color{blue}{S} & \color{blue}{O} \\
\end{array}
\\
\begin{array}{c c c c}
\color{blue}{N} \\
\color{blue}{E}\\
\color{blue}{S} \\
\color{blue}{O}
\end{array}
&
\left(
\begin{array}{c c c c}
0 & 0.5 & 0 & 0.5 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0.5 & 0 & 0.5 & 0
\end{array}
\right)
\end{array}\]
\end{example}

L'ensemble des états, \(E\), est formé de 4 états \{N, E, S, O\}. La probabilité de se déplacer à l'état \(E\) sachant qu'on se trouve à l'état \(N\) est:
\[
P(X_{n+1}=E|X_n=N)=p_{12}=0.5
\]
Le graphe orienté correspondant à cette matrice de transition est:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nn=}\KeywordTok{c}\NormalTok{(}\StringTok{"N"}\NormalTok{,}\StringTok{"E"}\NormalTok{, }\StringTok{"S"}\NormalTok{,}\StringTok{"O"}\NormalTok{)}
\NormalTok{P1=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\DecValTok{0}\NormalTok{),}\DecValTok{2}\NormalTok{), }\DataTypeTok{nc=}\DecValTok{4}\NormalTok{,}
          \DataTypeTok{dimnames =} \KeywordTok{list}\NormalTok{(nn,nn))}
\KeywordTok{plotmat}\NormalTok{(}\KeywordTok{t}\NormalTok{(P1), }\DataTypeTok{box.size =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{box.prop =} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{box.col =} \StringTok{"gray"}\NormalTok{, }
          \DataTypeTok{arr.pos =} \FloatTok{0.7}\NormalTok{, }\DataTypeTok{relsize =} \FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Calcul_Stochastique_files/figure-latex/unnamed-chunk-11-1.pdf}
\begin{example}
\protect\hypertarget{exm:unnamed-chunk-12}{}{\label{exm:unnamed-chunk-12} }La tendance d'un marché boursier peut être haussière (H), ou baissière (B) ou en consolidation (marché en range) (C). Le graphe associé est donné comme suit:
\end{example}
\includegraphics{Calcul_Stochastique_files/figure-latex/unnamed-chunk-13-1.pdf}

On déduit la matrice de transition
\[
P=\left( 
\begin{array}{ccc}
0.85 & 0.06 & 0.09 \\
0.05 & 0.87 & 0.08 \\
0.5 & 0.25 & 0.25
\end{array}
\right)
\]
On note qu'un jour haussier est suivi par un autre jour haussier dans 85\% des temps, par un jour baissier dans 6\% des temps et par un jour de consolidation dans 9\% des temps.
\begin{exercise}
\protect\hypertarget{exr:unnamed-chunk-14}{}{\label{exr:unnamed-chunk-14} }Dans un certain pays, il ne fait jamais beau deux jours de suite. Si un jour il fait beau, le lendemain il peut neiger ou pleuvoir avec autant de chances. Si un jour il pleut ou il neige, il y a une chance sur deux qu'il ait changement de temps le lendemain, et s'il y a changement, il y a une chance sur deux que ce soit pour du beau temps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Former une chaîne de Markov et en déterminer sa matrice de transition. Représenter le graphe orienté associé.
\item
  Si on suppose l'on a que deux états (beau temps et mauvais temps), déterminer la matrice de la nouvelle chaîne ainsi obtenue.
\end{enumerate}
\end{exercise}

\textbf{Solution 1.1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  On a l'ensemble des états suivants \(E=\{B,P,N \}\). Le temps pour un jour ne dépend que seulement de temps du jour précédent. On a donc un processus de Markov.
\end{enumerate}

Il ne fait jamais beau deux jours de suite \(\Longrightarrow P(X_{n+1}=B|X_n=B)=0\).

Si un jour il fait beau, le lendemain il peut neiger ou pleuvoir avec autant de chances \(\Longrightarrow P(X_{n+1}=P|X_n=B)=P(X_{n+1}=N|X_n=B)=0.5\).

Si un jour il pleut ou il neige, il y a une chance sur deux qu'il ait changement de temps le lendemain \(\Longrightarrow P(X_{n+1}=P|X_n=P)=P(X_{n+1}=N|X_n=N)=0.5\).

et s'il y a changement, il y a une chance sur deux que ce soit pour du beau temps \(P(X_{n+1}=B|X_n=P)=P(X_{n+1}=B|X_n=N)=0.5\times 0.5=0.25\).

Ainsi, la matrice stochastique est donnée par:
\[
  P=\left( 
  \begin{array}{ccc}
  0 & 0.5 & 0.5\\
  0.25 & 0.5 & 0.25\\
  0.25 & 0.25 & 0.5
  \end{array}
  \right)
  \]
et le graphe orienté associé est:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{noms=}\KeywordTok{c}\NormalTok{(}\StringTok{"B"}\NormalTok{,}\StringTok{"P"}\NormalTok{,}\StringTok{"N"}\NormalTok{)}
\NormalTok{PB=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\FloatTok{0.5}\NormalTok{), }\DataTypeTok{nc=}\DecValTok{3}\NormalTok{,}
          \DataTypeTok{dimnames =} \KeywordTok{list}\NormalTok{(noms,noms))}
\KeywordTok{plotmat}\NormalTok{(}\KeywordTok{t}\NormalTok{(PB), }\DataTypeTok{box.size =} \FloatTok{0.06}\NormalTok{, }\DataTypeTok{box.prop =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{box.col =} \StringTok{"gray"}\NormalTok{, }
          \DataTypeTok{arr.pos =} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{relsize =} \FloatTok{0.85}\NormalTok{,}\DataTypeTok{dtext =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Calcul_Stochastique_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Le nouvel ensemble des états est \(E_1=\{B, M \}\), \(M\) pour désigner mauvais temps (soit il pleut soit il neige).
  \[P(X_{n+1}=B|X_n=M)=P(X_{n+1}=B|X_n=P)+P(X_{n+1}=B|X_n=N)=0.5+0.5=1\]
  \[P(X_{n+1}=M|X_n=M)=P(X_{n+1}=P|X_n=P)+P(X_{n+1}=N|X_n=N) \]
\end{enumerate}

\hypertarget{loi-des-x_n}{%
\section{\texorpdfstring{Loi des \(X_n\)}{Loi des X\_n}}\label{loi-des-x_n}}

Le comportement d'une chaîne de Markov \(X\) dépend entièrement de sa matrice de transition \(P\), et de la position initiale \(X_0\). On appelle \(\mu_0\) la \(\color{blue}{\mathbf{\text{loi initiale}}}\) de \(X\), c'est une mesure définie par
\[
\mu_0(x)=\mathbb{P}(X_0=x)
\]
Connaissant \(\mu_0\) et \(P\), on peut calculer directement la loi de \(X_n\).

La distribution de \(X_1\) est:

\begin{align*} 
\mathbb{P}(X_1 = j) = \sum_{i=1}^N \mathbb{P}(X_1 = j | X_0 = i)\mathbb{P}(X_0 = i) \\
=
\sum_{i=1}^N \mu_0(i) p_{ij}=(\mu_0 P)_j\; \text{ pour tout }j
\end{align*}

La distribution de \(X_2\) est:

\begin{align*} 
\mathbb{P}(X_2 = j) = \sum_{i=1}^N \mathbb{P}(X_1 = j | X_0 = i)\mathbb{P}(X_0 = i) \\
=
\sum_{i=1}^N \mu_0(i) (P^2)_{ij}=(\mu_0 P^2)_j\; \text{ pour tout }j
\end{align*}

\begin{theorem}
\protect\hypertarget{thm:unnamed-chunk-16}{}{\label{thm:unnamed-chunk-16} }Soit \(\{X_0, X_1, X_2, \ldots \}\) une CM et \(P\) sa matrice de transition carré d'ordre \(N\). Si la distribution initiale, \(\mu_0\) est donnée, alors la distribution de probabilité de \(X_n\) est donnée par \(\mu_0 P^n\).
\[
X_0 \sim \mu_0 \Longrightarrow X_n \sim \mu_0 P
\]
\end{theorem}

\textbf{Probabilité d'une trajectoire}

Rappelons qu'une trajectoire est une séquence
de valeurs pour \(X_0, X_1,\ldots, X_n\). La propriété de Markov nous permet de trouver la probabilité de n'importe quelle trajectoire en multipliant la probabilité de départ et toutes les probabilités à un pas ultérieures.

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-17}{}{\label{prp:unnamed-chunk-17} }Pour toute suite \(\{x_0, x_1, \ldots , x_n\}\) dans \(E\), on a
\(P(X_0 = x_0, X_1 = x_1,X_2 = x_2, \ldots , X_n = x_n) =\mu_0(x_0)P(x_0, x_1)P(x_1, x_2)\ldots P(x_{n−1}, x_n)\).
\end{proposition}

\begin{theorem}[Equations de Chapman-Kolmogorov]
\protect\hypertarget{thm:unnamed-chunk-18}{}{\label{thm:unnamed-chunk-18} \iffalse (Equations de Chapman-Kolmogorov) \fi{} }Pour tout \$(i, j) \in E\^{}2 et tout couple \((m, n)\) d'entiers positifs, on a l'identité :
\[
\mathbb{P}(X_{m+n} = j|X_0 = i) = \sum_{k\in E}
\mathbb{P}(X_m = k|X_0 = i)\mathbb{P}(X_n = j|X_0 = k)\]
\[\text{ou encore }
p^{(m+n)}_{ij} = \sum_{k \in E} p^{(m)}_{ik} p^{(n)}_{kj} \text{ ou } (P^{m+n})_{ij}=(P^m)_{ik}(P^n)_{kj}\]
\end{theorem}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-19}{}{\label{exm:unnamed-chunk-19} }Soit une CM définie par la matrice de transition \[
  P=\left( 
  \begin{array}{cccc}
  0.2 & 0.4 & 0.1 & 0.3\\
  0 & 0.5 & 0.4 & 0.1\\
  0.1 & 0 & 0.6 & 0.3\\
  0.4 & 0.15 & 0.25 & 0.2
  \end{array}
    \right)
  \]
et de distribution initiale \(\mu_0 \sim (0.3,0.2,0.5,0)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Déterminer \(\mathbb{P}(X_2=2)\).
\item
  Déterminer la probabilité des trajectoires: 1,2,3,4 et 2,3,1,1.
\end{enumerate}
\end{example}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\mathbb{P}(X_2=2)=\left(\mu_0 P^2 \right)_{2}\).
\end{enumerate}

\begin{align*}
\text{Or } \mu_0 P^2=(0.3,0.2,0.5,0) \left( 
  \begin{array}{cccc}
  0.2 & 0.4 & 0.1 & 0.3\\
  0 & 0.5 & 0.4 & 0.1\\
  0.1 & 0 & 0.6 & 0.3\\
  0.4 & 0.15 & 0.25 & 0.2
  \end{array}
    \right) \left( 
  \begin{array}{cccc}
  0.2 & 0.4 & 0.1 & 0.3\\
  0 & 0.5 & 0.4 & 0.1\\
  0.1 & 0 & 0.6 & 0.3\\
  0.4 & 0.15 & 0.25 & 0.2
  \end{array}
    \right)\\
    = (0.167,0.193,0.41,0.23)\qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \quad \;
\end{align*}

D'où \(\mathbb{P}(X_2=2)=0.193\).

Sous R, le produit matriciel s'effectue à l'aide de la fonction \texttt{\%*\%}. Pour la puissance d'ordre \(n \geq 2\) d'une matrice carré, on peut utiliser la fonction \texttt{\%\^{}\%} définie ci-dessous.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{P4=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.1}\NormalTok{,.}\DecValTok{4}\NormalTok{,.}\DecValTok{4}\NormalTok{,.}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{,.}\DecValTok{15}\NormalTok{,.}\DecValTok{1}\NormalTok{,.}\DecValTok{4}\NormalTok{,.}\DecValTok{6}\NormalTok{,.}\DecValTok{25}\NormalTok{, }\FloatTok{.3}\NormalTok{,.}\DecValTok{1}\NormalTok{,.}\DecValTok{3}\NormalTok{,.}\DecValTok{2}\NormalTok{), }\DataTypeTok{nc=}\DecValTok{4}\NormalTok{)}
\NormalTok{mu0=}\KeywordTok{c}\NormalTok{(.}\DecValTok{3}\NormalTok{,.}\DecValTok{2}\NormalTok{,.}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{mu0}\OperatorTok{%*%}\NormalTok{P4}\OperatorTok{%*%}\NormalTok{P4  }\CommentTok{# %*% : produit matriciel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      [,1]  [,2] [,3] [,4]
[1,] 0.167 0.193 0.41 0.23
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# puissance nième d'une matrice carré}
\NormalTok{power_matrix=}\ControlFlowTok{function}\NormalTok{(A,n)\{}
 \ControlFlowTok{if}\NormalTok{(n}\OperatorTok{==}\DecValTok{0}\NormalTok{) }\KeywordTok{return}\NormalTok{(}\KeywordTok{diag}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(A))))}
 \ControlFlowTok{if}\NormalTok{(n}\OperatorTok{==}\DecValTok{1}\NormalTok{) }\KeywordTok{return}\NormalTok{(A)}
 \ControlFlowTok{if}\NormalTok{(n}\OperatorTok{>}\DecValTok{1}\NormalTok{) }\KeywordTok{return}\NormalTok{(A}\OperatorTok{%*%}\KeywordTok{power_matrix}\NormalTok{(A,(n}\DecValTok{-1}\NormalTok{)))}
\NormalTok{\}}
\StringTok{"%^%"}\NormalTok{<-power_matrix}
\NormalTok{P4}\OperatorTok{%^%}\DecValTok{3}     \CommentTok{# P4^3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       [,1]  [,2]   [,3]  [,4]
[1,] 0.1415 0.259 0.3835 0.216
[2,] 0.1385 0.193 0.4405 0.228
[3,] 0.1925 0.163 0.3885 0.256
[4,] 0.1670 0.244 0.3670 0.222
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(\mathbb{P}(1,2,3,4)=\mathbb{P}(X_0=1)\times P_{12}\times P_{23}\times P_{34}= 0.3 \times 0.4 \times 0.4 \times 0.3 =\) 0.0144.
\end{enumerate}

\(\mathbb{P}(2,3,1,1)=\mathbb{P}(X_0=2)\times P_{23}\times P_{31}\times P_{11}= 0.2 \times 0.4 \times 0.1 \times 0.2 =\) 0.0016.

Pour le calcul de la probabilité d'une trajectoire donnée sous R, on peut utiliser la fonction suivante:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ProbTraj<-}\ControlFlowTok{function}\NormalTok{(traj,mu0,X0, P)\{}
\NormalTok{  n<-}\KeywordTok{length}\NormalTok{(traj)}\OperatorTok{-}\DecValTok{1}
\NormalTok{  pi<-}\OtherTok{NULL}
  \ControlFlowTok{for}\NormalTok{(k }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n) pi[k]<-P[traj[k],traj[k}\OperatorTok{+}\DecValTok{1}\NormalTok{]]}
\NormalTok{mu0[X0]}\OperatorTok{*}\KeywordTok{prod}\NormalTok{(pi)}
\NormalTok{\}}
\KeywordTok{ProbTraj}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{),mu0,}\DataTypeTok{X0=}\DecValTok{1}\NormalTok{,P4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0144
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ProbTraj}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),mu0,}\DataTypeTok{X0=}\DecValTok{2}\NormalTok{,P4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0016
\end{verbatim}

\begin{exercise}
\protect\hypertarget{exr:unnamed-chunk-22}{}{\label{exr:unnamed-chunk-22} } On considère une CM à trois états dont la matrice de transition est la suivante :
\[ P=\left( 
  \begin{array}{ccc}
0.6 & 0.2 & 0.2 \\
0.4 & 0 & 0.6 \\
0 & 0.8 & 0.2
\end{array}
\right)\]
Calculer \(\mathbb{P}(X_2=3|X_0=1)\).
\end{exercise}

\textbf{Solution 1.2}

\(\mathbb{P}(X_2=3|X_0=1)\) est la probabilité de se déplacer de l'état 1 à l'état 2 en \textbf{deux} étapes. Donc les trajectoires possibles sont: (1,2,3); (1,1,3) ou (1,3,3) avec \(\mu_0=(1,0,0)\).
\begin{align*}
\mathbb{P}(X_2=3|X_0=1)= \left( P^2\right)_{13} =\left( 
  \begin{array}{ccc}
0.6 & 0.2 & 0.2 \\
. & . & . \\
. & . & .
\end{array}
\right)\left( 
  \begin{array}{ccc}
. & . & 0.2 \\
. & . & 0.4 \\
. & . & 0.2
\end{array}
\right)\\
= 0.6 \times 0.2 + 0.2 \times 0.6 +0.2 \times 0.2 = 0.28.
\end{align*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{P=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.6}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.2}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.2}\NormalTok{,}\FloatTok{0.6}\NormalTok{,}\FloatTok{0.2}\NormalTok{),}\DataTypeTok{nc=}\DecValTok{3}\NormalTok{)}
\NormalTok{P[}\DecValTok{1}\NormalTok{,]}\OperatorTok{%*%}\NormalTok{P[,}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]
[1,] 0.28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ou encore}
\CommentTok{# (1,2,3); (1,1,3); (1,3,3)}
\KeywordTok{ProbTraj}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}\DataTypeTok{X0=}\DecValTok{1}\NormalTok{,P)}\OperatorTok{+}\KeywordTok{ProbTraj}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}\DataTypeTok{X0=}\DecValTok{1}\NormalTok{,P)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ProbTraj}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}\DataTypeTok{X0=}\DecValTok{1}\NormalTok{,P)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.28
\end{verbatim}

\begin{exercise}
\protect\hypertarget{exr:unnamed-chunk-24}{}{\label{exr:unnamed-chunk-24} } On considère une chaîne de Markov à deux états dont la matrice de transition est la suivante :
\[ P=\left( 
  \begin{array}{cc}
0.4 & 0.6 \\
0.6 & 0.4 
\end{array}
\right)\]
Calculer la probabilité de l'événement \(A_3\) de passer pour \(n \leq 5\) trois fois par l'état 2 si la loi initiale est \(\mu_0=(0.3,0.7)\).
\end{exercise}

\textbf{Solution 1.3}

\(A_3=\{n \leq 5\), on passe 3 fois par l'état 2 \(\}\).

Tout d'abord, déterminons les différentes possibilités.

Si l'état initial est l'état \(\color{blue}{1}\), on aura les possibilités suivantes:

\(x_1^1=(1, 1, 2, 2, 2)\), \(x_1^2=(1, 2,1, 2, 2)\), \(x_1^3=(1 ,2 ,2 ,1 , 2)\) et \(x_1^4=(1 , 2, 2, 2, 1)\)

D'où \(\mathbb{P}_1(A_3)=\mathbb{P}(X=x_1^1)+\mathbb{P}(X=x_1^2)+\mathbb{P}(X=x_1^3)+\mathbb{P}(X=x_1^4)\)

Avec \(\mathbb{P}(X=x_1^1)=\mathbb{P}(X_0=1)\times p_{11}\times p_{12}\times p_{22}\times p_{22}=0.3 \times 0.4 \times 0.6 \times 0.4 \times 0.4=\) 0.01152;

\(\mathbb{P}(X=x_1^2)=\mathbb{P}(X_0=1) \times p_{12}\times p_{21}\times p_{12}\times p_{22}=0.3\times 0.6^3 \times 0.4 =\) 0.02592;

\(\mathbb{P}(X=x_1^3)=\mathbb{P}(X_0=1)\times p_{12}\times p_{22}\times p_{21}\times p_{12}=0.3\times 0.6 \times 0.4 \times 0.6^2 =\) 0.02592;

\(\mathbb{P}(X=x_1^4)=\mathbb{P}(X_0=1)\times p_{12}\times p_{22}\times p_{22}\times p_{21}=0.3\times 0.6^2 \times 0.4^2 =\) 0.01728;

Donc \(\mathbb{P}_1(A_3)= 0.01152+0.02592+0.02592+0.01728=\) 0.08064.

Si l'état initial est l'état \(\color{blue}{2}\), on aura:

\(x_2^1=(2,1, 1, 2, 2)\), \(x_2^2=(2, 1, 2, 1,2)\), \(x_2^3=(2 , 1 , 2, 2, 1)\), \(x_2^4=(2, 2, 1, 2, 1)\), \(x_2^5=(2, 2 , 1 , 1 , 2)\) et \(x_2^6=(2, 2, 2 , 1 , 1)\).

D'où \(\mathbb{P}_2(A_3)=P(X=x_2^1)+P(X=x_2^2)+P(X=x_2^3)+P(X=x_2^4)+P(X=x_2^5)+P(X=x_2^6)\).

\(\mathbb{P}_2(A_3)=0.3192\).

Ainsi \(\mathbb{P}(A_3)=\mu_0(1)\times \mathbb{P}_1(A_3)+\mu_0(2)\times \mathbb{P}_2(A_3)=\) 0.247632.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab1=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{nr=}\DecValTok{5}\NormalTok{)}
\NormalTok{mu0=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{,}\FloatTok{0.7}\NormalTok{)}
\NormalTok{P2=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.4}\NormalTok{,}\FloatTok{0.6}\NormalTok{,}\FloatTok{0.6}\NormalTok{,}\FloatTok{0.4}\NormalTok{),}\DataTypeTok{nc=}\DecValTok{2}\NormalTok{)}
\NormalTok{(}\DataTypeTok{probs1=}\KeywordTok{apply}\NormalTok{(tab1,}\DecValTok{2}\NormalTok{,ProbTraj,mu0,}\DecValTok{1}\NormalTok{,P2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.01152 0.02592 0.02592 0.01728
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(probs1)    }\CommentTok{# P1(A3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.08064
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab2=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{nr=}\DecValTok{5}\NormalTok{)}
\NormalTok{(}\DataTypeTok{probs2=}\KeywordTok{apply}\NormalTok{(tab2,}\DecValTok{2}\NormalTok{,ProbTraj,mu0,}\DecValTok{2}\NormalTok{,P2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.04032 0.09072 0.06048 0.06048 0.04032 0.02688
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(probs2)    }\CommentTok{# P2(A3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3192
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{PA3=mu0}\OperatorTok{%*%}\KeywordTok{c}\NormalTok{(}\KeywordTok{sum}\NormalTok{(probs1),}\KeywordTok{sum}\NormalTok{(probs2)) ; }\KeywordTok{as.vector}\NormalTok{(PA3)    }\CommentTok{#P(A3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.247632
\end{verbatim}

\hypertarget{classification-des-uxe9tats}{%
\section{Classification des états}\label{classification-des-uxe9tats}}

L'espace des états d'une CM peut être partitionné en un ensemble de classes communicantes disjointes.

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-26}{}{\label{def:unnamed-chunk-26} }On dit que l'état \(j\) est \(\color{blue}{\mathbf{\text{accessible}}}\) à partir de l'état \(i\), s'il existe un entier \(n \geq 0\) tel que \(P^{(n)}_{ij} >0\). On note \(i \longrightarrow j\).

Sur le graphe, si \(i \neq j\), \(i\longrightarrow j\) s'il existe un chemin (orienté) du sommet \(i\) vers le sommet \(j\).

Si \(j\) est accessible à partir de \(i\) et \(i\) est accessible depuis \(j\), on dit que \(i\) et \(j\) \(\color{blue}{\mathbf{\text{communiquent}}}\) et on note \(i \longleftrightarrow j\).
\end{definition}

On note que si \(i \longrightarrow k\) et \(k \longrightarrow j\), alors \(i \longrightarrow j\) (la relation d'accessibilité est transitive).

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-27}{}{\label{def:unnamed-chunk-27} }Les états \(i\) et \(j\) sont dans la même classe communicante si \(i \longleftrightarrow j\).
\end{definition}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-28}{}{\label{exm:unnamed-chunk-28} }Trouvez les classes communicantes associées au diagramme de transition suivant.
\end{example}

\begin{center}\includegraphics[width=0.5\linewidth]{images/graph2} \end{center}

D'après le diagramme, on remarque que \(1 \longleftrightarrow 2\), \(2 \longleftrightarrow 3\) et \(4 \longleftrightarrow 5\). Donc on a deux classes communicantes \(\{1,2,3\}\) et \(\{4,5 \}\).

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-30}{}{\label{def:unnamed-chunk-30} }Une classe d'états communicante est fermée s'il est impossible de quitter
cette classe. Autrement dit, la classe \(C\) communicante est fermée si \(p_{ij} = 0\) pour tout \(i \in C\) et \(j \notin C\).
\end{definition}

Dans l'exemple précédent:

\begin{itemize}
\tightlist
\item
  La classe \(\{1,2,3\}\) n'est pas fermée car on peut la quitter (\(2 \longrightarrow 4\)).
\item
  La classe \(\{4,5\}\) est fermée car on ne peut pas la quitter.
\end{itemize}

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-31}{}{\label{def:unnamed-chunk-31} }Si la chaîne de Markov ne possède qu'une unique classe, c'est à dire que tous
ses éléments communiquent, la chaîne sera dite \(\color{blue}{\mathbf{\text{irréductible}}}\).

Un état \(i\) est dite \(\color{blue}{\mathbf{\text{absorbant}}}\) si \(\{i\}\) est une classe fermée.
\end{definition}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-32}{}{\label{exm:unnamed-chunk-32} }On considère la CMD à tois états 1, 2, 3 et de matrice stochastique
\[
  P=\left( 
    \begin{array}{ccc}
    1/2 & 1/2 & 0 \\
    1/2 & 1/4 & 1/4 \\
    0 & 1/3 & 2/3\\
    \end{array}
    \right)
\]
Comme \(1 \longleftrightarrow 2\) et \(2 \longleftrightarrow 3\), alors cette CM est \textbf{irréductible}.
\end{example}

Pour étudier la classification d'une CMD sous R, on peut procéder comme suit:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# install.packeges("markovchain")   # Installation de l'extension markovchain}
\KeywordTok{library}\NormalTok{(markovchain)}
\NormalTok{pp=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{), }\DataTypeTok{nc=}\DecValTok{3}\NormalTok{, }
          \DataTypeTok{dimnames =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{,}\StringTok{"2"}\NormalTok{,}\StringTok{"3"}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{,}\StringTok{"2"}\NormalTok{,}\StringTok{"3"}\NormalTok{)))}
\NormalTok{cm1=}\KeywordTok{new}\NormalTok{(}\StringTok{"markovchain"}\NormalTok{, }\DataTypeTok{transitionMatrix=}\NormalTok{pp)}
\KeywordTok{is.irreducible}\NormalTok{(cm1)  }\CommentTok{# tester si la CM est irreductible}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-33}{}{\label{exm:unnamed-chunk-33} }Soit la CMD à quatre états définie par la matrice stochastique
\[
  P=\left( 
    \begin{array}{cccc}
    1/2 & 1/2 & 0 &0\\
    1/2 & 1/2 & 0 & 0 \\
   0& 0 & 1/4 & 3/4\\
    0 & 0 & 0 & 1
    \end{array}
    \right)
\]
Cette CM possède trois classes: \(\{1,2\}\), \(\{3\}\) et \(\{4\}\), donc elle est \textbf{non irréductible}.

L'états 4 est \textbf{absorbant} car \(\{4\}\) est une classe fermée.
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p15=}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\FloatTok{0.75}\NormalTok{,}\DecValTok{1}\NormalTok{), }\DataTypeTok{nc=}\DecValTok{4}\NormalTok{, }
           \DataTypeTok{dimnames =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{,}\StringTok{"2"}\NormalTok{,}\StringTok{"3"}\NormalTok{,}\StringTok{"4"}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{,}\StringTok{"2"}\NormalTok{,}\StringTok{"3"}\NormalTok{,}\StringTok{"4"}\NormalTok{)))}
\NormalTok{cm2=}\KeywordTok{new}\NormalTok{(}\StringTok{"markovchain"}\NormalTok{, }\DataTypeTok{transitionMatrix=}\NormalTok{ p15)}
\KeywordTok{is.irreducible}\NormalTok{(cm2)  }\CommentTok{# tester si la CM est irréductible}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{absorbingStates}\NormalTok{(cm2) }\CommentTok{# déterminer les états absorbants}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "4"
\end{verbatim}

\hypertarget{temps-dabsorption}{%
\section{Temps d'absorption}\label{temps-dabsorption}}

Dans cette section on se pose la question suivante : Etant donné une chaîne \(X\) et \(x\) dans l'espace d'états \(E\), quel est le temps moyen (éventuellement infini) que met \(X\) à arriver au temps \(x\).

\hypertarget{temps-darruxeat}{%
\subsection{Temps d'arrêt}\label{temps-darruxeat}}

Pour \(x \in E\) on définit le temps aléatoire
\[
T_x = \min\{n \geq 0 : X_n = x\},
\]
premier moment où la chaîne atteint l'état \(x\).

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-34}{}{\label{def:unnamed-chunk-34} }Soit \(A\) un sous ensemble de l'espace d'états \(E\). Le \textbf{temps d'atteinte} de \(A\) est la variable aléatoire \(T_A\) définie par:
\[
T_A = \min\{n \geq 0 : X_n \in A \},
\]
\end{definition}

Notons que la probabilité d'atteindre \(A\) dépuis \(i\) est \(h_{A|i} = P(T_A < \infty |X_0 = i)\).

\(T_A\) est le temps nécessaire pour atteindre l'ensemble \(A\) pour la première fois. \(T_A\) peut prendre les valeurs \(0,1,2,\ldots , \infty\).

Si la chaîne ne peut jamais atteindre \(A\), alors \(T_A= \infty\).

Le temps d'atteinte est appelé aussi \textbf{temps d'arrêt}. Si \(A\) est une classe fermée, \(T_A\) sera appelé le \textbf{temps d'absorption} et \(h_{A|i}\) la \textbf{probabilité d'absorption}.

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-35}{}{\label{def:unnamed-chunk-35} }Le \textbf{temps moyen d'atteinte} de \(A\), à partir de \(i\) est:
\[ m_{iA}=\mathbb{E}\left(T_A | X_0=i \right)\]
\end{definition}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-36}{}{\label{exm:unnamed-chunk-36} }On considère la chaîne suivante
\end{example}

\begin{center}\includegraphics[width=0.45\linewidth]{images/graphe3} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Déterminer le vecteur des probabilités d'ateinte de l'état 4.
\item
  Déterminer le temps moyen d'atteinte de \(A=\{1,4\}\), à partie de 2.
\end{enumerate}

\hypertarget{simulation-dune-chauxeene-de-markov-discruxe8te}{%
\section{Simulation d'une chaîne de Markov discrète}\label{simulation-dune-chauxeene-de-markov-discruxe8te}}

\hypertarget{exemple-illustratif}{%
\subsection{Exemple illustratif}\label{exemple-illustratif}}

L'idée générale pour simuler une chaînes de Markov discrète peut être illustrée par un exemple simple à 2 états. Supposons que notre espace d'états est \{1,2\} et que la matrice de transition est:
\[ P=\left(
\begin{array}{cc}
0.2 & 0.8 \\
0.4 & 0.6
\end{array}
\right)\]

Supposons maintenant que notre chaîne de Markov commence à l'état 1 de sorte que \(X_0 = 1\). Puisque nous commençons à l'état 1, nos probabilités de transition sont définies par la première ligne de \(P\). Notre chaîne peut soit rester à l'état 1 avec une probabilité \(P_{11}=0.2\), soit passer à l'état 2 avec une probabilité \(P_{12}=0.8\). Par conséquent, pour simuler \(X_1\), il faut générer une variable aléatoire selon les probabilités \(P_{11} = P (X_1 = 1 | X_0 = 1) = 0.2\) et \(P_{12} = P (X_1 = 2 | X_0 = 0) = 0.8\).

En général, nous pouvons générer n'importe quelle variable aléatoire discrète selon un ensemble de probabilités \(p = \{p_1,\ldots, p_K\}\) avec la méthode de transformation inverse. Notez également que cela équivaut à prendre un seul tirage à partir d'une distribution multinomiale avec un vecteur de probabilité \(p\) - nous utilisons cette méthode dans l'algorithme ci-dessous.

\textbf{Algorithme}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Obtenir la matrice de transition de probabilité \(S\times S\), \(P\).
\item
  Définir \(t=0\).
\item
  Choisissez un état initial \(X_0 = x_0\).
\item
  pour \(t=1, \ldots , T\):

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Obtenir la ligne de \(P\) correspondante à l'état actuel \(X_t\)
  \item
    Génère \(X_{t + 1}\) à partir d'une distribution multinomiale avec un vecteur de probabilité égal à la ligne que nous avons obtenue ci-dessus.
  \end{enumerate}
\end{enumerate}

Nous implémentons cet algorithm dans la fonction suivante:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# simuler des CMD selon la matrice de transition P}
\NormalTok{sim_CMD <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{( P, }\DataTypeTok{N =} \DecValTok{50}\NormalTok{, }\DataTypeTok{x0=}\DecValTok{1}\NormalTok{ ) \{}
  \CommentTok{# nombre des états}
\NormalTok{  n_etats <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(P)}
\NormalTok{  etats <-}\StringTok{ }\KeywordTok{numeric}\NormalTok{(N)}
  \CommentTok{# valeur de l'état initial }
\NormalTok{  etats[}\DecValTok{1}\NormalTok{] <-}\StringTok{ }\NormalTok{x0}
  \ControlFlowTok{for}\NormalTok{(t }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{N) \{}
    \CommentTok{# vecteur de prob pour simuller l'état suivant X_\{t+1\}}
\NormalTok{    p <-}\StringTok{ }\NormalTok{P[etats[t}\DecValTok{-1}\NormalTok{], ]}
    \CommentTok{## tirer depuis la distribution multinomiale et déterminer l'état}
\NormalTok{    etats[t] <-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{rmultinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, p) }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(etats)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{simulation-de-lexemple-illustratif}{%
\subsubsection{Simulation de l'exemple illustratif}\label{simulation-de-lexemple-illustratif}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(P <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.6}\NormalTok{), }\DataTypeTok{nc=}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,]  0.2  0.8
[2,]  0.4  0.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim1<-}\KeywordTok{sim_CMD}\NormalTok{(P,}\DataTypeTok{N=}\DecValTok{100}\NormalTok{, }\DataTypeTok{x0=}\DecValTok{1}\NormalTok{)}
\KeywordTok{head}\NormalTok{(sim1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 2 1 2 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim11<-}\KeywordTok{replicate}\NormalTok{(}\KeywordTok{sim_CMD}\NormalTok{(P,}\DataTypeTok{N=}\DecValTok{50}\NormalTok{, }\DataTypeTok{x0=}\DecValTok{1}\NormalTok{),}\DataTypeTok{n=}\DecValTok{100}\NormalTok{)}
\KeywordTok{mean}\NormalTok{(sim11[}\DecValTok{2}\NormalTok{,sim11[}\DecValTok{1}\NormalTok{,]}\OperatorTok{==}\DecValTok{1}\NormalTok{]}\OperatorTok{==}\DecValTok{1}\NormalTok{) }\CommentTok{# p11=p(X_1=1|X_0=1)=0.2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(sim11[}\DecValTok{1}\NormalTok{,sim11[}\DecValTok{1}\NormalTok{,]}\OperatorTok{==}\DecValTok{1}\NormalTok{]}\OperatorTok{==}\DecValTok{1}\NormalTok{) }\CommentTok{# p12=p(X_1=1|X_0=1)=0.2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\hypertarget{processus-de-poisson}{%
\chapter{Processus de poisson}\label{processus-de-poisson}}

\hypertarget{processus-gaussien}{%
\chapter{Processus Gaussien}\label{processus-gaussien}}

\hypertarget{applications}{%
\chapter{Applications}\label{applications}}

Some \emph{significant} applications are demonstrated in this chapter.

\hypertarget{example-one}{%
\section{Example one}\label{example-one}}

\hypertarget{example-two}{%
\section{Example two}\label{example-two}}

\hypertarget{bibliographie}{%
\chapter*{Bibliographie}\label{bibliographie}}
\addcontentsline{toc}{chapter}{Bibliographie}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-bremaud}{}%
Pierre, Brémaud. 2009. \emph{Initiation Aux Probabilités et Aux Chaînes de Markov}. 2e édition entièrement révisée. Berlin Heidelberg: Springer.

\leavevmode\hypertarget{ref-R-base}{}%
R Core Team. 2020. \emph{R: A Language and Environment for Statistical Computing}. Vienna, Austria: R Foundation for Statistical Computing. \url{https://www.R-project.org/}.

\leavevmode\hypertarget{ref-Ross97}{}%
Ross, Sheldon M. 2019. \emph{Introduction to Probability Models}. Twelfth. San Diego, CA, USA: Academic Press.

\leavevmode\hypertarget{ref-ross1996stochastic}{}%
Ross, S. M. 1996. \emph{Stochastic Processes}. Wiley Series in Probability and Statistics: Probability and Statistics. Wiley.

\leavevmode\hypertarget{ref-R-diagram}{}%
Soetaert, Karline. 2020a. \emph{Diagram: Functions for Visualising Simple Graphs (Networks), Plotting Flow Diagrams}. \url{https://CRAN.R-project.org/package=diagram}.

\leavevmode\hypertarget{ref-R-shape}{}%
---------. 2020b. \emph{Shape: Functions for Plotting Graphical Shapes, Colors}. \url{https://CRAN.R-project.org/package=shape}.

\leavevmode\hypertarget{ref-R-markovchain}{}%
Spedicato, Giorgio Alfredo, Tae Seung Kang, Sai Bhargav Yalamanchi, Deepak Yadav, and Ignacio Cordón. 2021. \emph{Markovchain: Easy Handling Discrete Time Markov Chains}. \url{https://CRAN.R-project.org/package=markovchain}.

\leavevmode\hypertarget{ref-tijms2003first}{}%
Tijms, H. C. 2003. \emph{A First Course in Stochastic Models}. Wiley. \url{https://books.google.tn/books?id=WibF8iVHaiMC}.

\end{document}
